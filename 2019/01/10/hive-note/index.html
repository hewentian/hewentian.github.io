<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>hive 学习笔记 | Tim Ho&#39;s Technology Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Hive 介绍hive的官方文档中有对hive的详细介绍，这里不再赘述。我们用一句话描述如下：The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure">
<meta name="keywords" content="hive">
<meta property="og:type" content="article">
<meta property="og:title" content="hive 学习笔记">
<meta property="og:url" content="https://github.com/hewentian/2019/01/10/hive-note/index.html">
<meta property="og:site_name" content="Tim Ho&#39;s Technology Blog">
<meta property="og:description" content="Hive 介绍hive的官方文档中有对hive的详细介绍，这里不再赘述。我们用一句话描述如下：The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure">
<meta property="og:locale" content="en-US">
<meta property="og:updated_time" content="2020-03-16T01:55:41.617Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="hive 学习笔记">
<meta name="twitter:description" content="Hive 介绍hive的官方文档中有对hive的详细介绍，这里不再赘述。我们用一句话描述如下：The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Tim Ho&#39;s Technology Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">心如止水</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives/">Archives</a>
        
          <a class="main-nav-link" href="/categories/">Categories</a>
        
          <a class="main-nav-link" href="/tags/">Tags</a>
        
          <a class="main-nav-link" href="/about/">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://github.com/hewentian"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-hive-note" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/10/hive-note/" class="article-date">
  <time datetime="2019-01-10T14:30:12.000Z" itemprop="datePublished">2019-01-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      hive 学习笔记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Hive-介绍"><a href="#Hive-介绍" class="headerlink" title="Hive 介绍"></a>Hive 介绍</h3><p>hive的<a href="https://hive.apache.org/" target="_blank" rel="noopener">官方文档</a>中有对hive的详细介绍，这里不再赘述。我们用一句话描述如下：<br>The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive.</p>
<h3 id="hive-的安装"><a href="#hive-的安装" class="headerlink" title="hive 的安装"></a>hive 的安装</h3><p>安装过程参考这里：<br><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></p>
<p>hive依赖于HADOOP，我们在上一篇<a href="../../../../2019/01/01/hadoop-cluster-ha/">hadoop 集群的搭建HA</a>的基础上安装hive。</p>
<p>首先下载hive，我们下载的时候，要选择适合我们HADOOP版本的hive，我们下载的稳定版为<a href="http://archive.apache.org/dist/hive/hive-1.2.2/" target="_blank" rel="noopener">apache-hive-1.2.2-bin.tar.gz</a>，我们将在HADOOP集群的namenode上面安装，即在master机器上面安装。将压缩包传到<code>/home/hadoop/</code>目录下。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/</span><br><span class="line">$ tar xzvf apache-hive-1.2.2-bin.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>解压后得到目录<code>apache-hive-1.2.2-bin</code>，我们看下压缩包中的内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin</span><br><span class="line">$ ls</span><br><span class="line">bin  conf  examples  hcatalog  lib  LICENSE  NOTICE  README.txt  RELEASE_NOTES.txt  scripts</span><br><span class="line">$</span><br><span class="line">$ ls conf/</span><br><span class="line">beeline-log4j.properties.template  hive-env.sh.template                 hive-log4j.properties.template</span><br><span class="line">hive-default.xml.template          hive-exec-log4j.properties.template  ivysettings.xml</span><br></pre></td></tr></table></figure></p>
<p>配置HADOOP_HOME：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin/conf/</span><br><span class="line">$ cp hive-default.xml.template hive-site.xml</span><br><span class="line">$ cp hive-env.sh.template hive-env.sh</span><br><span class="line">$ vi hive-env.sh</span><br><span class="line"></span><br><span class="line">HADOOP_HOME=/home/hadoop/hadoop-2.7.3</span><br></pre></td></tr></table></figure></p>
<p>到这里，hive就配置好了，可以运行了。但，不妨看下下面的<code>配置hive元数据的存储位置</code>，因为生产环境一般是要配置的。</p>
<h3 id="配置hive元数据的存储位置（可选配置）"><a href="#配置hive元数据的存储位置（可选配置）" class="headerlink" title="配置hive元数据的存储位置（可选配置）"></a>配置hive元数据的存储位置（可选配置）</h3><p>hive默认将元数据存储在<code>derby</code>数据库中（hive安装包自带），当然我们也可以选择存储在其他数据库，如mysql中。下面演示一下：<br>首先在MYSQL数据库中创建一个数据库，用于存储hive的元数据，我们就将库名创建为hive：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE DATABASE IF NOT EXISTS hive COLLATE = &apos;utf8_general_ci&apos; CHARACTER SET = &apos;utf8&apos;;</span><br><span class="line">mysql&gt; GRANT ALL ON hive.* TO &apos;hive&apos;@&apos;%&apos; IDENTIFIED BY &apos;hive&apos;;</span><br><span class="line">mysql&gt; GRANT ALL ON hive.* TO &apos;hive&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;hive&apos;;</span><br><span class="line">mysql&gt; FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure></p>
<p>然后配置hive使用mysql存储元数据：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin/conf/</span><br><span class="line">$ vi hive-site.xml</span><br></pre></td></tr></table></figure></p>
<p>修改下面部分，假定我们的数据库地址、用户名和密码如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://mysql.hewentian.com:3306/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      JDBC connect string for a JDBC metastore.</span><br><span class="line">      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.</span><br><span class="line">      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>最后，将mysql连接JDBC的jar包<a href="http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.42/mysql-connector-java-5.1.42.jar" target="_blank" rel="noopener">mysql-connector-java-5.1.42.jar</a>放到<code>apache-hive-1.2.2-bin/lib</code>目录下</p>
<p>好了，以上这部分是<strong>可选配置</strong>部分。</p>
<h3 id="启动hive"><a href="#启动hive" class="headerlink" title="启动hive"></a>启动hive</h3><p>初次启动hive，需在HDFS中创建几个目录，用于存储hive的数据，我们在安装hive的master节点执行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/hadoop-2.7.3/</span><br><span class="line">$ ./bin/hdfs dfs -mkdir /tmp</span><br><span class="line">$ ./bin/hdfs dfs -mkdir -p /user/hive/warehouse</span><br><span class="line">$</span><br><span class="line">$ ./bin/hdfs dfs -chmod g+w /tmp</span><br><span class="line">$ ./bin/hdfs dfs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure></p>
<p>初始化元数据存储相关信息，hive默认使用内置的<code>derby</code>数据库存储元数据。这里使用<code>mysql</code>，如果要使用默认的，则则将下面的<code>mysql</code>修改成<code>derby</code>即可。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin/bin</span><br><span class="line">$ ./schematool -dbType mysql -initSchema</span><br><span class="line"></span><br><span class="line">Metastore connection URL:	 jdbc:mysql://mysql.hewentian.com:3306/hive</span><br><span class="line">Metastore Connection Driver :	 com.mysql.jdbc.Driver</span><br><span class="line">Metastore connection User:	 hive</span><br><span class="line">Starting metastore schema initialization to 1.2.0</span><br><span class="line">Initialization script hive-schema-1.2.0.mysql.sql</span><br><span class="line">Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure></p>
<p>正式启动hive<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin/bin</span><br><span class="line">$ ./hive</span><br></pre></td></tr></table></figure></p>
<p>启动的时候可能会报如下错误：</p>
<pre><code>Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: ${system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D
    at org.apache.hadoop.fs.Path.initialize(Path.java:205)
    at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:171)
    at org.apache.hadoop.hive.ql.session.SessionState.createSessionDirs(SessionState.java:659)
    at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:582)
    at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:549)
    at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:750)
    at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
Caused by: java.net.URISyntaxException: Relative path in absolute URI: ${system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D
    at java.net.URI.checkPath(URI.java:1823)
    at java.net.URI.&lt;init&gt;(URI.java:745)
    at org.apache.hadoop.fs.Path.initialize(Path.java:202)
    ... 12 more
</code></pre><p>解决方法如下，先建目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin/</span><br><span class="line">$ mkdir iotmp</span><br></pre></td></tr></table></figure></p>
<p>将<code>hive-site.xml</code>中</p>
<ol>
<li>包含<code>${system:java.io.tmpdir}</code>的配置项替换为上面的路径<code>/home/hadoop/apache-hive-1.2.2-bin/iotmp</code>，一共有4处；</li>
<li>包含<code>${system:user.name}</code>的配置项替换为<code>hadoop</code>。<br>修改项如下：<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/apache-hive-1.2.2-bin/iotmp/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Local scratch space for Hive jobs<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/apache-hive-1.2.2-bin/iotmp/$&#123;hive.session.id&#125;_resources<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Temporary local directory for added resources in the remote file system.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/apache-hive-1.2.2-bin/iotmp/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Location of Hive run time structured log file<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.logging.operation.log.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/apache-hive-1.2.2-bin/iotmp/hadoop/operation_logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Top level directory where operation logs are stored if logging functionality is enabled<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>重新启动hive：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin/bin</span><br><span class="line">$ ./hive</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/home/hadoop/apache-hive-1.2.2-bin/lib/hive-common-1.2.2.jar!/hive-log4j.properties</span><br><span class="line">hive&gt; show databases;</span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">Time taken: 0.821 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt; </span><br><span class="line">    &gt; use default;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.043 seconds</span><br><span class="line">hive&gt; </span><br><span class="line">    &gt; show tables;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.094 seconds</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure></p>
<p>至此，hive安装成功。从上面可知，hive有一个默认的数据库<code>default</code>，并且里面一张表也没有。</p>
<h3 id="hive初体验"><a href="#hive初体验" class="headerlink" title="hive初体验"></a>hive初体验</h3><ul>
<li><p>A longer tutorial that covers more features of HiveQL:<br><a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Tutorial</a></p>
</li>
<li><p>The HiveQL Language Manual:<br><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual</a></p>
</li>
</ul>
<h3 id="创建数据库："><a href="#创建数据库：" class="headerlink" title="创建数据库："></a>创建数据库：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; CREATE DATABASE IF NOT EXISTS tim;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.323 seconds</span><br><span class="line">hive&gt;</span><br><span class="line">    &gt; show databases;</span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">tim</span><br><span class="line">Time taken: 0.025 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure>
<p>同样，我们可以在HDFS中查看到：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/hadoop-2.7.3/</span><br><span class="line">$ ./bin/hdfs dfs -ls /user/hive/warehouse</span><br><span class="line">Found 1 items</span><br><span class="line">drwxrwxr-x   - hadoop supergroup          0 2019-01-01 19:32 /user/hive/warehouse/tim.db</span><br></pre></td></tr></table></figure></p>
<h3 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; use tim;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.042 seconds</span><br><span class="line">hive&gt; </span><br><span class="line">    &gt; CREATE TABLE IF NOT EXISTS t_user (</span><br><span class="line">    &gt; id INT,</span><br><span class="line">    &gt; name STRING COMMENT <span class="string">'user name'</span>,</span><br><span class="line">    &gt; age INT COMMENT <span class="string">'user age'</span>,</span><br><span class="line">    &gt; sex STRING COMMENT <span class="string">'user sex'</span>,</span><br><span class="line">    &gt; birthday DATE COMMENT <span class="string">'user birthday'</span>,</span><br><span class="line">    &gt; address STRING COMMENT <span class="string">'user address'</span></span><br><span class="line">    &gt; )</span><br><span class="line">    &gt; COMMENT <span class="string">'This is the use info table'</span></span><br><span class="line">    &gt; ROW FORMAT DELIMITED</span><br><span class="line">    &gt;  FIELDS TERMINATED BY <span class="string">'\t'</span></span><br><span class="line">    &gt; STORED AS TEXTFILE;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.521 seconds</span><br><span class="line">hive&gt; </span><br><span class="line">    &gt; show tables;</span><br><span class="line">OK</span><br><span class="line">t_user</span><br><span class="line">Time taken: 0.035 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>
<h3 id="查看表结构"><a href="#查看表结构" class="headerlink" title="查看表结构"></a>查看表结构</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc t_user;</span><br><span class="line">OK</span><br><span class="line">id                  	int</span><br><span class="line">name                	string              	user name</span><br><span class="line">age                 	int                 	user age</span><br><span class="line">sex                 	string              	user sex</span><br><span class="line">birthday            	date                	user birthday</span><br><span class="line">address             	string              	user address</span><br><span class="line">Time taken: 0.074 seconds, Fetched: 6 row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>
<h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; INSERT INTO TABLE t_user(id, name, age, sex, birthday, address) VALUES(1, <span class="string">'Tim Ho'</span>, 23, <span class="string">'M'</span>, <span class="string">'1989-05-01'</span>, <span class="string">'Higher Education Mega Center South, Guangzhou city, Guangdong Province'</span>);</span><br><span class="line">Query ID = hadoop_20190102160558_640a90a7-9122-4650-af78-acb436e2643b</span><br><span class="line">Total <span class="built_in">jobs</span> = 3</span><br><span class="line">Launching Job 1 out of 3</span><br><span class="line">Number of reduce tasks is <span class="built_in">set</span> to 0 since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1546186928725_0015, Tracking URL = http://hadoop-host-master:8088/proxy/application_1546186928725_0015/</span></span><br><span class="line"><span class="string">Kill Command = /home/hadoop/hadoop-2.7.3/bin/hadoop job  -kill job_1546186928725_0015</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2019-01-02 16:06:08,341 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2019-01-02 16:06:14,565 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.39 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 1 seconds 390 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1546186928725_0015</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to: hdfs://hadoop-cluster-ha/user/hive/warehouse/tim.db/t_user/.hive-staging_hive_2019-01-02_16-05-58_785_7094384272339204067-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table tim.t_user</span></span><br><span class="line"><span class="string">Table tim.t_user stats: [numFiles=1, numRows=1, totalSize=96, rawDataSize=95]</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched: </span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1   Cumulative CPU: 1.39 sec   HDFS Read: 4763 HDFS Write: 162 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 1 seconds 390 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">Time taken: 17.079 seconds</span></span><br><span class="line"><span class="string">hive&gt;</span></span><br></pre></td></tr></table></figure>
<p>执行插入操作它会产生一个mapReduce任务。</p>
<h3 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select * from t_user;</span><br><span class="line">OK</span><br><span class="line">1	Tim Ho	23	M	1989-05-01	Higher Education Mega Center South, Guangzhou city, Guangdong Province</span><br><span class="line">Time taken: 0.196 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt; </span><br><span class="line">    &gt; select * from t_user <span class="built_in">where</span> name=<span class="string">'Tim Ho'</span>;</span><br><span class="line">OK</span><br><span class="line">1	Tim Ho	23	M	1989-05-01	Higher Education Mega Center South, Guangzhou city, Guangdong Province</span><br><span class="line">Time taken: 0.258 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt; </span><br><span class="line">    &gt; select count(*) from t_user;</span><br><span class="line">Query ID = hadoop_20190102161100_d60df721-539d-4e5b-a3db-a4951ac884b4</span><br><span class="line">Total <span class="built_in">jobs</span> = 1</span><br><span class="line">Launching Job 1 out of 1</span><br><span class="line">Number of reduce tasks determined at compile time: 1</span><br><span class="line">In order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="built_in">set</span> hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">In order to <span class="built_in">limit</span> the maximum number of reducers:</span><br><span class="line">  <span class="built_in">set</span> hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">In order to <span class="built_in">set</span> a constant number of reducers:</span><br><span class="line">  <span class="built_in">set</span> mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1546186928725_0016, Tracking URL = http://hadoop-host-master:8088/proxy/application_1546186928725_0016/</span><br><span class="line">Kill Command = /home/hadoop/hadoop-2.7.3/bin/hadoop job  -<span class="built_in">kill</span> job_1546186928725_0016</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage-1: number of mappers: 1; number of reducers: 1</span><br><span class="line">2019-01-02 16:11:10,739 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">2019-01-02 16:11:16,997 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.05 sec</span><br><span class="line">2019-01-02 16:11:23,280 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 2.37 sec</span><br><span class="line">MapReduce Total cumulative CPU time: 2 seconds 370 msec</span><br><span class="line">Ended Job = job_1546186928725_0016</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 2.37 sec   HDFS Read: 7285 HDFS Write: 2 SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: 2 seconds 370 msec</span><br><span class="line">OK</span><br><span class="line">1</span><br><span class="line">Time taken: 24.444 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>
<p>由上面可知，执行简单的查询操作不会启动mapReduce，但执行像COUNT这样的统计操作将会产生一个mapReduce。</p>
<h3 id="从文件中导入数据"><a href="#从文件中导入数据" class="headerlink" title="从文件中导入数据"></a>从文件中导入数据</h3><p>语法：</p>
<pre><code>LOAD DATA [LOCAL] INPATH &apos;filepath&apos; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]
</code></pre><p>我们可以按定义表结构时的使用的字段分隔符(\t)，将数据存放在文本文件里，然后使用LOAD命令来导入。例如我们将数据存放在<code>/home/hadoop/user.txt</code>中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2	scott	25	M	1977-10-21	USA</span><br><span class="line">3	tiger	21	F	1977-08-12	UK</span><br></pre></td></tr></table></figure></p>
<p>然后在hive中执行LOAD命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; LOAD DATA LOCAL INPATH <span class="string">'/home/hadoop/user.txt'</span> INTO TABLE t_user;</span><br><span class="line">Loading data to table tim.t_user</span><br><span class="line">Table tim.t_user stats: [numFiles=2, numRows=0, totalSize=151, rawDataSize=0]</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.214 seconds</span><br><span class="line">hive&gt; </span><br><span class="line">    &gt; select * from t_user;</span><br><span class="line">OK</span><br><span class="line">1	Tim Ho	23	M	1989-05-01	Higher Education Mega Center South, Guangzhou city, Guangdong Province</span><br><span class="line">2	scott	25	M	1977-10-21	USA</span><br><span class="line">3	tiger	21	F	1977-08-12	UK</span><br><span class="line">Time taken: 0.085 seconds, Fetched: 3 row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="通过JAVA代码操作hive"><a href="#通过JAVA代码操作hive" class="headerlink" title="通过JAVA代码操作hive"></a>通过JAVA代码操作hive</h3><p>HQL脚本通常有以下几种方式执行：</p>
<ol>
<li>hive -e “hql”; </li>
<li>hive -f “hql.file”;</li>
<li>hive jdbc code.</li>
</ol>
<p>本节主要讲讲如何通过java来操作hive，首先启动HiveServer2，hiveserver2命令未来可用于替代hive命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin/bin</span><br><span class="line">$ ./hiveserver2</span><br></pre></td></tr></table></figure></p>
<p>启动后，你可能会发现，啥也没输出。这时我们在另一个SHELL窗口中启动beelie<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hadoop/apache-hive-1.2.2-bin/bin</span><br><span class="line">$ ./beeline -u jdbc:hive2://hadoop-host-master:10000 -n hadoop -p hadoop</span><br><span class="line"></span><br><span class="line">Connecting to jdbc:hive2://hadoop-host-master:10000</span><br><span class="line">Connected to: Apache Hive (version 1.2.2)</span><br><span class="line">Driver: Hive JDBC (version 1.2.2)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 1.2.2 by Apache Hive</span><br><span class="line">0: jdbc:hive2://hadoop-host-master:10000&gt; </span><br><span class="line">0: jdbc:hive2://hadoop-host-master:10000&gt; show databases;</span><br><span class="line">+----------------+--+</span><br><span class="line">| database_name  |</span><br><span class="line">+----------------+--+</span><br><span class="line">| default        |</span><br><span class="line">| tim            |</span><br><span class="line">+----------------+--+</span><br><span class="line">2 rows selected (0.217 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop-host-master:10000&gt; use tim;</span><br><span class="line">No rows affected (0.08 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop-host-master:10000&gt; show tables;</span><br><span class="line">+-----------+--+</span><br><span class="line">| tab_name  |</span><br><span class="line">+-----------+--+</span><br><span class="line">| t_user    |</span><br><span class="line">+-----------+--+</span><br><span class="line">1 row selected (0.071 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop-host-master:10000&gt; select * from t_user;</span><br><span class="line">+------------+--------------+-------------+-------------+------------------+-------------------------------------------------------------------------+--+</span><br><span class="line">| t_user.id  | t_user.name  | t_user.age  | t_user.sex  | t_user.birthday  |                             t_user.address                              |</span><br><span class="line">+------------+--------------+-------------+-------------+------------------+-------------------------------------------------------------------------+--+</span><br><span class="line">| 1          | Tim Ho       | 23          | M           | 1989-05-01       | Higher Education Mega Center South, Guangzhou city, Guangdong Province  |</span><br><span class="line">| 2          | scott        | 25          | M           | 1977-10-21       | USA                                                                     |</span><br><span class="line">| 3          | tiger        | 21          | F           | 1977-08-12       | UK                                                                      |</span><br><span class="line">+------------+--------------+-------------+-------------+------------------+-------------------------------------------------------------------------+--+</span><br><span class="line">3 rows selected (0.219 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop-host-master:10000&gt;</span><br></pre></td></tr></table></figure></p>
<p>由上面可知，和在hive命令下的操作是一样的。上面的命令也可以没有<code>-p hadoop</code>这个参数，这个可以在<code>hive-site.xml</code>中配置。</p>
<p>java代码操作hive的例子在这里：<a href="https://github.com/hewentian/bigdata/blob/master/codes/hadoop-demo/src/main/java/com/hewentian/hadoop/utils/HiveUtil.java">HiveUtil.java</a>、<a href="https://github.com/hewentian/bigdata/blob/master/codes/hadoop-demo/src/main/java/com/hewentian/hadoop/hive/HiveDemo.java">HiveDemo.java</a></p>
<h3 id="后台方式启动hive"><a href="#后台方式启动hive" class="headerlink" title="后台方式启动hive"></a>后台方式启动hive</h3><p>For versions 1.2 and above, <code>hive</code> is deprecated and the <code>hiveserver2</code> command should be used directly.</p>
<p>So the correct way to start hiveserver2 in background is now:</p>
<pre><code>cd /home/hadoop/apache-hive-1.2.2-bin/bin
nohup ./hiveserver2 &amp;
</code></pre><p>Or with output to a log file:</p>
<pre><code>nohup ./hiveserver2 &gt; hive.log &amp;
</code></pre><p>未完待续……</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2019/01/10/hive-note/" data-id="ck7ttggr0000zcq3kin09dnp6" class="article-share-link">Partager</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/">hive</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/01/20/hbase-cluster/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          hbase 集群的搭建
        
      </div>
    </a>
  
  
    <a href="/2019/01/01/hadoop-cluster-ha/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">hadoop 集群的搭建HA</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/bigdata/">bigdata</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/container/">container</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/db/">db</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web-server/">web server</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/01/14/spark-note/">spark 学习笔记</a>
          </li>
        
          <li>
            <a href="/2019/12/30/scala-note/">scala 学习笔记</a>
          </li>
        
          <li>
            <a href="/2019/07/26/docker-note/">docker 学习笔记</a>
          </li>
        
          <li>
            <a href="/2019/06/10/nginx-note/">nginx 学习笔记</a>
          </li>
        
          <li>
            <a href="/2019/01/20/hbase-cluster/">hbase 集群的搭建</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">link</h3>
    <div class="widget">
      <li><a href="https://github.com/hewentian" title="Tim Ho's Blog">我的github</a></li>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Tim Ho<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives/" class="mobile-nav-link">Archives</a>
  
    <a href="/categories/" class="mobile-nav-link">Categories</a>
  
    <a href="/tags/" class="mobile-nav-link">Tags</a>
  
    <a href="/about/" class="mobile-nav-link">About</a>
  
</nav>
    

<!-- <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script> -->
<script src="//code.jquery.com/jquery-2.2.4.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>