<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Tim Ho&#39;s Technology Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="my personal blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Tim Ho&#39;s Technology Blog">
<meta property="og:url" content="https://github.com/hewentian/index.html">
<meta property="og:site_name" content="Tim Ho&#39;s Technology Blog">
<meta property="og:description" content="my personal blog">
<meta property="og:locale" content="en-US">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tim Ho&#39;s Technology Blog">
<meta name="twitter:description" content="my personal blog">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Tim Ho&#39;s Technology Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">心如止水</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives/">Archives</a>
        
          <a class="main-nav-link" href="/categories/">Categories</a>
        
          <a class="main-nav-link" href="/tags/">Tags</a>
        
          <a class="main-nav-link" href="/about/">About</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://github.com/hewentian"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-kafka-intro" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/12/kafka-intro/" class="article-date">
  <time datetime="2018-11-12T01:04:49.000Z" itemprop="datePublished">2018-11-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/12/kafka-intro/">kafka 介绍</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这是一篇译文，因英文水平有限，翻译未免有不足之处。如果想看原文，请访问这里：<br><a href="http://kafka.apache.org/intro" target="_blank" rel="noopener">http://kafka.apache.org/intro</a></p>
<p><strong> 如果想简单体验一下kafka，可以阅读我上两篇介绍的 <a href="../../../../2018/10/24/kafka-standalone/">kafka 单节点安装</a>、<a href="../../../../2018/10/27/kafka-cluster/">kafka 集群的搭建</a> </strong></p>
<h3 id="Apache-Kafka是一个分布式的流媒体平台，那么，它到底指的是什么呢？"><a href="#Apache-Kafka是一个分布式的流媒体平台，那么，它到底指的是什么呢？" class="headerlink" title="Apache Kafka是一个分布式的流媒体平台，那么，它到底指的是什么呢？"></a>Apache Kafka是一个分布式的流媒体平台，那么，它到底指的是什么呢？</h3><p>流媒体平台有3个主要的性能指标：</p>
<ol>
<li>发布和订阅消息流，类似于消息队列或者企业消息系统；</li>
<li>以容错方式、持久化存储流数据；</li>
<li>实时处理流数据。</li>
</ol>
<p>kafka通常应用于两种广泛的场景：</p>
<ol>
<li>在系统或应用程序之间构建可靠的用于传输实时数据的管道; </li>
<li>构建实时的流数据处理程序，来转换或处理数据流。</li>
</ol>
<h3 id="为了弄清楚kafka到底是怎样完成这些功能的，从下面开始我们钻研和探究一下kafka的功能"><a href="#为了弄清楚kafka到底是怎样完成这些功能的，从下面开始我们钻研和探究一下kafka的功能" class="headerlink" title="为了弄清楚kafka到底是怎样完成这些功能的，从下面开始我们钻研和探究一下kafka的功能"></a>为了弄清楚kafka到底是怎样完成这些功能的，从下面开始我们钻研和探究一下kafka的功能</h3><p>首先，了解一下几个概念：</p>
<ol>
<li>kafka可以以集群方式运行于一台或者多台服务器，这些服务器可以分布在不同的数据中心；</li>
<li>kafka集群将流式数据分类存储，这种类别通常被称为主题；</li>
<li>每一条消息由键、值和时间戳组成。</li>
</ol>
<p><img src="/img/kafka-1.png" alt="" title="来源：http://kafka.apache.org/20/images/kafka-apis.png"></p>
<p>kafka有4个核心API：</p>
<ol>
<li><a href="http://kafka.apache.org/documentation.html#producerapi" target="_blank" rel="noopener">Producer API</a>允许应用程序将一条消息发布到一个或者多个kafka主题中；</li>
<li><a href="http://kafka.apache.org/documentation.html#consumerapi" target="_blank" rel="noopener">Consumer API</a>允许应用程序订阅一个或者多个主题，并且处理被发往其中的数据流；</li>
<li><a href="http://kafka.apache.org/documentation/streams" target="_blank" rel="noopener">Streams API</a>允许一个应用充当流式处理器：从作为输入流的一个或多个主题中消费消息，然后将处理过的消息输出到另一个或多个主题中。高效地将输入流的数据转换、传输到输出流中；</li>
<li><a href="http://kafka.apache.org/documentation.html#connect" target="_blank" rel="noopener">Connector API</a>允许建立和重用已有的生产者或消费者，它们连接着某个kafka主题，而这些主题是和已存在的应用和数据系统连接着的。例如，关系数据库的连接器将会捕获对表的每一个修改。</li>
</ol>
<p>在kafka中，客户端和服务器端的通讯是通过一个简单、高效、语言无关的<a href="https://kafka.apache.org/protocol.html" target="_blank" rel="noopener">TCP协议</a>完成的。此协议是有版本代差的，但新版本向后兼容旧版本。我们提供一个JAVA客户端连接kafka，但是其他语言的客户端也提供。消费者和服务端建立的是长连接。</p>
<h3 id="主题和日志（存储策略）"><a href="#主题和日志（存储策略）" class="headerlink" title="主题和日志（存储策略）"></a>主题和日志（存储策略）</h3><p>我们首先钻研一下kafka中为处理流记录而提供的核心抽象概念–主题。</p>
<p>主题就是一个分类，或者说是专为发布消息而命名的。在kafka中主题通常有多个订阅者，也就是说一个主题可以有零个、一个或者多个消费者，这些消费者都订阅写往其中的消息。</p>
<p>对每一个主题，kafka集群都使用分区存储，像下面这样：<br><img src="/img/kafka-2.png" alt="" title="来源：http://kafka.apache.org/20/images/log_anatomy.png"></p>
<p>每一个分区中的消息都是按顺序存储的，持续往该分区中存放的数据的顺序都是不可改变的，结构化存储。分区中的每一条消息都会被分配一个有序的ID号，被称为偏移量，用于唯一标示该分区中的每一条消息。</p>
<p>kafka集群会持久化发布到它的每一条消息，无论它们是否已经被消费过，可以通过配置文件配置该消息存放多久。例如，如果保存策略被设置为2天，那么当一条消息发布2天之内，它都是可以被消费的，只是一旦被消费之后，它就会被删掉以释放空间。kafka是持续高性能的，这与存储于它的数据大小关系不大，因此长期保存数据，都是没问题的。</p>
<p><img src="/img/kafka-3.png" alt="" title="来源：http://kafka.apache.org/20/images/log_consumer.png"></p>
<p>实际上，唯一存储于每一个消费者中的元数据是偏移量或者该消费者在这个分区中访问存储数据的位置。偏移量由消费者控制：通常，消费者中保存的偏移量随着它消费消息，将呈线性增长。但是，实际上，由于这个偏移量是由消费者控制的，所以它可以指定它消费的任何位置上的消息。例如：一个消费者可以重置到一个旧的偏移量来处理旧的数据或者跳过大部分记录，然后从当前位置开始消费消息。</p>
<p>这个组合功能意味着kafka消费者是轻量级的，它们的连接和断开对集群和其他消费者影响极小。例如，你可以使用我们的命令行工具去不停地显示最新添加到某个主题的内容，而这，不会对任何订阅这个主题的消费者产生影响。</p>
<p>分区在存储中扮演着不同的目的：首先，它允许存储的数据量超过单台服务器允许的规模。每个单独的分区能储存的数据量取决于它所在的服务器磁盘的大小等因素，但是一个主题可以有多个分区，因此它能储存任意数量的数据。其次，分区充当并行处理的单元–同时能处理的并发数。</p>
<h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><p>一个主题的分区分布于kafka集群中的多台服务器中，每一台服务器都可以处理数据和向共享分区发送请求。为了容错，每一个分区都可以配置一定的副本数。</p>
<p>每一个分区都有一台服务器担当主服务器，可以有零个或者多个从服务器。主服务器处理对分区的所有读和写请求，从服务器由主服务器调度。如果主服务器挂掉了，从服务器中会自动产生一个新的主服务器。集群中的每一台服务器既充当某个分区的主服务器，又充当其他分区的从服务器，所以整个集群是负载均衡的。</p>
<h3 id="地域复制"><a href="#地域复制" class="headerlink" title="地域复制"></a>地域复制</h3><p>kafka的MirrorMaker为你的集群提供跨地域复制支持。使用MirrorMaker，消息可以跨越多个数据中心或者不同的云区进行同步。你可以在主从模式下用于备份和恢复，或者在主主模式下使数据更靠近你的用户，或者支持数据本地请求。</p>
<h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><p>生产者往它们选定的主题中发送消息的时候，应该为每一条消息指定它要发送到的分区。我们可以使用环形策略，简单地使数据平均分配于所有分区中，也可以根据消息中的语义来自动地选择分区。接下来将会说下分区的使用。</p>
<h3 id="消息者"><a href="#消息者" class="headerlink" title="消息者"></a>消息者</h3><p>我们可以对消费者分组，每个组有一个组名。每一条发送到指定主题中的消息，都会被订阅了这个主题的同一个组中的一个消费者消费。同一个组中的消费者可以在同一台机器或者多台机器中。</p>
<p>如果所有消费者实例都在同一个组中，那么所有消息都会高效地平均发送到所有消费者实例。<br>如果所有消费者实例分布在不同的组中，那么每条消息都会被广播到所有组中的一个消费者。</p>
<p><img src="/img/kafka-4.png" alt="" title="来源：http://kafka.apache.org/20/images/consumer-groups.png"></p>
<p>上图所示：该kafka集群有2台服务器，4个分区（P0-P3），有2个消费者组。消费者组A有2个消费者实例，而消费者组B有4个。</p>
<p>通常，主题都会有少量的消费者组，在逻辑上看，一个消费者组就是一个订阅者。每个组包含多个消费者，这能很好的实现扩展和容错。在订阅的语义上：订阅者只不过是一群消费者，而不是一个。</p>
<p>消费的方式在kafka中的实现是通过将分区分配给所有消费者实例，因此在任何时刻，每一个实例都是一个”公平共享“分区的唯一消费者。维护组中成员关系的方式在kafak中是通过kafka协议自动实现的：如果新的实例加进组，那么它将从其他组员中获取一个分区（如果这个组员处理两个以上分区）；如果一个实例挂掉了，那么它所处理的分区将被分配给组中剩下的成员们。</p>
<p>kafka对每一个分区中的消息都只提供一个总的顺序，同一个主题中不同分区中的顺序各不相同。每个分区排序组织该分区中数据的能力能满足大部分应用的需求。但是，如果你想要一个所有消息的总顺序，可以通过为这个主题设置一个分区来实现，不过，这意味着一个消费者组中只能有一个消费者来处理该主题的消息。</p>
<h3 id="多租户架构"><a href="#多租户架构" class="headerlink" title="多租户架构"></a>多租户架构</h3><p>你可以以多租户架构方式部署kafka。多租户架构可以通过配置，来指定哪个主题可以生产和消费数据，并且支持设置操作指标。管理员可以定义和限制所有请求的指标，以控制客户端能使用的服务器资源数。</p>
<p>更多相关信息，请访问<a href="https://kafka.apache.org/documentation/#security" target="_blank" rel="noopener">这里</a>。</p>
<h3 id="保证"><a href="#保证" class="headerlink" title="保证"></a>保证</h3><p>在高层次看kafka提供以下保证：</p>
<ol>
<li>一个生产者发往指定主题中指定分区中的消息，将会按照它们发送的顺序出现。例如：如果一个生产者发送消息M1、M2，如果M1先发送，那么M1将会首先出现在那个分区中，并且M1的顺序号要比M2的小；</li>
<li>消费者按顺序读取存储在主题中的消息；</li>
<li>如果一个主题有 N 个副本，那么我们能承受高达 N-1 台服务器同时挂掉，而不会丢失任何消息。</li>
</ol>
<p>更多关于这些保证的描述将在相关章节中详细说明。</p>
<h3 id="kafka作为一个消息系统"><a href="#kafka作为一个消息系统" class="headerlink" title="kafka作为一个消息系统"></a>kafka作为一个消息系统</h3><p>kafka的流媒体概念与传统的企业消息系统相比有什么不同？</p>
<p>消息传输在传统上有2种模型：队列和发布-订阅。在队列模型中，一组消费者从一台服务器读取消息，每个消息只会发送到其中一个消费者；在发布-订阅模型中，每条消息都会广播到所有消费者。这两种模型各自都有优势和不足。队列的优势是允许你将消息平均分配给所有消费者处理，这能扩展系统的处理能力。不幸的是，队列不能有多个订阅者，消息一旦被其中一个消费者读取就会被删掉。发布-订阅模型允许你将消息广播到所有消费者，这种方式不能扩展处理能力，因为每条消息都会被发送到所有订阅者。</p>
<p>消费者组的概念在kafka中通常包含上述两种概念。对队列来说，消费者组允许你将数据平均分配给所有消费者组来处理；对发布-订阅来说，kafka允许你将消息广播到所有消费者组。</p>
<p>kafka模型的优势是每个主题都有这两种属性：它能扩展处理能力，同时也支持多个订阅者。我们不需要选择其中一个，或者另外一个。</p>
<p>kafka相比于传统的消息系统，它更能保证消息的顺序。</p>
<p>传统队列会将消息按顺序保存在服务器上，如果多个消费者同时消费这个队列，那么服务器将按消息的存储顺序来分发给消费者。然而，尽管服务器按顺序分发消息，但是消息是异步的发送到每个消费者的，所以不同的消费者接收到消息的顺序可能不同。这意味着，在并行处理的情况下，消息的顺序将不能保证。在消息系统中通常有一个概念：唯一消费者，它允许只有一个消费者消费一个队列，当然这也意味着这种情况下不存在并行处理。</p>
<p>kafka在这方面做得比较好。在主题中，它有一个并行的概念–分区。kafka既能保证消息的顺序，又能在多个消费者之间保持负载均衡。通过将主题的分区分配给指定的消费者组，每个分区只能被消费者组中的一个消费者消费，来实现的。这样，我们能确保这个消费者是这个分区的唯一消费者和按顺序消费这个分区中的消息。尽管主题有很多个分区，我们仍能在多个消费者实例之间保持负载均衡。值得注意的是，消费者组中消费者的数量不能多于分区数。</p>
<h3 id="kafka作为一个存储系统"><a href="#kafka作为一个存储系统" class="headerlink" title="kafka作为一个存储系统"></a>kafka作为一个存储系统</h3><p>任何允许发布与消费消息分离的消息队列，实际上充当了目前使用的消息存储系统。kafka的不同之处在于它还是一个非常优秀的存储系统。</p>
<p>写入kafka的数据将会写入磁盘，并且进行副本复制以实现容错。kafka允许生产者等待确认，在收到回复之后才会认为写成功，并且即使写入的服务器失败了，也能保证这条消息是存在的。</p>
<p>kafka能很好地使用磁盘结构来扩容：无论服务器上有 50KB 还是 50TB 的持久化数据，kafka的性能都是一样的，不会随着数据的增多而出现性能下降。</p>
<p>由于kafka可以大规模的存储数据，并且允许客户控制其读取位置，您可以将kafka作为一种专用于高性能、低延迟提交日志存储，并且能复制和传播的分布式文件系统。</p>
<p>更多关于kafka的提交日志存储和副本复制的设计，请访问<a href="https://kafka.apache.org/documentation/#design" target="_blank" rel="noopener">这里</a>。</p>
<h3 id="kafka作为一个流媒体处理系统"><a href="#kafka作为一个流媒体处理系统" class="headerlink" title="kafka作为一个流媒体处理系统"></a>kafka作为一个流媒体处理系统</h3><p>kafka仅仅提供读取、写入和存储数据流是不够的，最终目的是实现流的实时处理。</p>
<p>在kafka中，流处理器是指持续地从输入主题获取数据流，对获取到的数据流执行某种处理，并将处理过的数据，持续地输出到输出主题中。</p>
<p>例如，零售店的应用程序可能会将销售额和货物作为输入流，通过相关计算，然后输出重新排序和根据此数据计算的价格调整的流。</p>
<p>可以直接使用生产者和消费者的相关API进行简单处理。但是，对于更复杂的转换，kafka提供了完全集成的Streams API。这允许构建一些应用程序去执行非普通处理任务、计算流的聚合或者将流连接在一起。</p>
<p>它能有效地解决此类应用程序面临的难题：处理无序数据，在代码更改时重新处理输入流，执行有状态计算等。</p>
<p>流式API构建在kafka提供的核心基础功能上：它使用生产者和消费者API进行输入，使用kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。</p>
<h3 id="把碎片整合在一起"><a href="#把碎片整合在一起" class="headerlink" title="把碎片整合在一起"></a>把碎片整合在一起</h3><p>将消息传递、存储和流处理组合在一起可能看起来没多大用处，但它对于kafka作为流媒体平台的作用至关重要。</p>
<p>像HDFS这种分布式文件系统允许存储静态文件以进行批处理。kafka系统是高效的，它允许存储和处理过去的历史数据。</p>
<p>传统的企业消息系统允许处理你订阅之后到达的数据。以这种方式构建的应用程序只能处理在它订阅之后到达的未来数据。</p>
<p>kafka结合了这两种功能，这种组合对于kafka作为流媒体应用程序平台以及流数据管道的使用至关重要。</p>
<p>通过组合存储和低延迟订阅，流应用程序可以以相同的方式处理过去和未来的数据。也就是说，单个应用程序也可以处理历史存储的数据，而不是在它处理到达最后一条记录时结束，它可以在未来数据到达时继续处理。这就是流处理包含批处理以及消息驱动应用程序的一般概念。</p>
<p>同样，对于流数据管道，通过组合订阅实时事件，可以将kafka用作极低延迟的管道; 另外，能够可靠地存储数据，也使得可以将其用于必须保证安全的核心数据的传输，或者与仅定期加载数据的离线系统或可能长时间停机以进行扩展和维护集成。它的流处理能力使它可以实时的转换数据。</p>
<p>更多关于kafka提供的保证、API和功能的信息，请参阅其余的<a href="http://kafka.apache.org/documentation.html" target="_blank" rel="noopener">文档</a>。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/11/12/kafka-intro/" data-id="cjogzpslb0017vv2i3qdhhc0v" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kafka-cluster" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/27/kafka-cluster/" class="article-date">
  <time datetime="2018-10-27T05:11:43.000Z" itemprop="datePublished">2018-10-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/27/kafka-cluster/">kafka 集群的搭建</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本篇将说说kafka集群的搭建，如果你只是想简单体验一下kafka，可以直接使用我在上一篇介绍的 <a href="../../../../2018/10/24/kafka-standalone/">kafka 单节点安装</a> 即可。</p>
<p>但是，如果你想在生产环境中使用，那么搭建一个集群可能更适合你。下面将说说kafka集群的安装使用，kafka同样是使用前面例子使用的<code>2.0.0</code>版本，我在一台机器上安装，所以这是伪集群，当修改为真集群的时候，只要将IP地址修改下即可，下面会说明。</p>
<p>首先，你得搭建 zookeeper 集群，因为高版本的kafka中内置了zookeeper组件，所以我们直接使用kafka中内置的zookeeper组件搭建zookeeper集群。但是，你也可以使用zookeeper独立的安装包来搭建zookeeper集群。两者的搭建方法都是一样的，可以参考 <a href="../../../../2017/12/06/zookeeper-install-cluster/">zookeeper集群版安装方法</a></p>
<h3 id="计划在一台Ubuntu-Linux服务器上部署3台kafka服务器，分别为kafka1-kafka2-kafka3"><a href="#计划在一台Ubuntu-Linux服务器上部署3台kafka服务器，分别为kafka1-kafka2-kafka3" class="headerlink" title="计划在一台Ubuntu Linux服务器上部署3台kafka服务器，分别为kafka1, kafka2, kafka3"></a>计划在一台<code>Ubuntu Linux</code>服务器上部署3台<code>kafka</code>服务器，分别为<code>kafka1</code>, <code>kafka2</code>, <code>kafka3</code></h3><p>因为三台<code>kafka</code>服务器的配置都差不多，所以我们先设置好一台<code>kafka1</code>的配置，再将其复制成<code>kafka2</code>, <code>kafka3</code>并修改其中的配置即可。</p>
<p>下面使用kafka内置的zookeeper组件搭建zookeeper集群，我们将kafka的所有服务器都放在同一个目录下：</p>
<h3 id="1-建目录，如下："><a href="#1-建目录，如下：" class="headerlink" title="1.建目录，如下："></a>1.建目录，如下：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD</span><br><span class="line">$ mkdir kafkaCluster</span><br></pre></td></tr></table></figure>
<h3 id="2-将kafka-2-12-2-0-0-tgz放到-home-hewentian-ProjectD-kafkaCluster目录下，并执行如下脚本解压"><a href="#2-将kafka-2-12-2-0-0-tgz放到-home-hewentian-ProjectD-kafkaCluster目录下，并执行如下脚本解压" class="headerlink" title="2.将kafka_2.12-2.0.0.tgz放到/home/hewentian/ProjectD/kafkaCluster目录下，并执行如下脚本解压"></a>2.将<code>kafka_2.12-2.0.0.tgz</code>放到<code>/home/hewentian/ProjectD/kafkaCluster</code>目录下，并执行如下脚本解压</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster</span><br><span class="line">$ tar xzvf kafka_2.12-2.0.0.tgz</span><br><span class="line"></span><br><span class="line">$ ls</span><br><span class="line">kafka_2.12-2.0.0  kafka_2.12-2.0.0.tgz</span><br><span class="line"></span><br><span class="line">$ rm kafka_2.12-2.0.0.tgz</span><br><span class="line">$ mv kafka_2.12-2.0.0/ kafka1  <span class="comment"># 为方便起见，将其命名为 kafka1</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> kafka1/</span><br><span class="line">$ mkdir -p data/zk     <span class="comment"># 存放zookeeper数据的目录</span></span><br><span class="line">$ mkdir -p data/kafka  <span class="comment"># 存放kafka数据的目录</span></span><br><span class="line">$ mkdir logs           <span class="comment"># 新解压的 kafka 没有此目录，需手动创建。因为重定向的日志logs/zookeeper.log需要此目录</span></span><br></pre></td></tr></table></figure>
<h3 id="3-修改-home-hewentian-ProjectD-kafkaCluster-kafka1-config-zookeeper-properties并在其中修改如下内容："><a href="#3-修改-home-hewentian-ProjectD-kafkaCluster-kafka1-config-zookeeper-properties并在其中修改如下内容：" class="headerlink" title="3.修改/home/hewentian/ProjectD/kafkaCluster/kafka1/config/zookeeper.properties并在其中修改如下内容："></a>3.修改<code>/home/hewentian/ProjectD/kafkaCluster/kafka1/config/zookeeper.properties</code>并在其中修改如下内容：</h3><pre><code>tickTime=2000
initLimit=10
syncLimit=5
dataDir=/home/hewentian/ProjectD/kafkaCluster/kafka1/data/zk  # 这里必须为绝对路径，否则有可能无法启动
clientPort=2181                                               # 这台服务器的端口为2181这里为默认值
server.1=127.0.0.1:2888:3888
server.2=127.0.0.1:2889:3889
server.3=127.0.0.1:2890:3890
</code></pre><h3 id="4-在-home-hewentian-ProjectD-kafkaCluster-kafka1-data-zk目录下建myid文件并在其中输入1，只输入1，代表server-1"><a href="#4-在-home-hewentian-ProjectD-kafkaCluster-kafka1-data-zk目录下建myid文件并在其中输入1，只输入1，代表server-1" class="headerlink" title="4.在/home/hewentian/ProjectD/kafkaCluster/kafka1/data/zk目录下建myid文件并在其中输入1，只输入1，代表server.1"></a>4.在<code>/home/hewentian/ProjectD/kafkaCluster/kafka1/data/zk</code>目录下建<code>myid</code>文件并在其中输入1，只输入1，代表server.1</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka1/data/zk</span><br><span class="line">$ vi myid</span><br></pre></td></tr></table></figure>
<p>这样第一台服务器已经配置完毕。</p>
<h3 id="5-接下来我们将kafka1复制为kafka2-kafka3"><a href="#5-接下来我们将kafka1复制为kafka2-kafka3" class="headerlink" title="5.接下来我们将kafka1复制为kafka2, kafka3"></a>5.接下来我们将<code>kafka1</code>复制为<code>kafka2</code>, <code>kafka3</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster</span><br><span class="line">$ cp -r kafka1 kafka2</span><br><span class="line">$ cp -r kafka1 kafka3</span><br></pre></td></tr></table></figure>
<h3 id="6-将kafka2-data-zk目录下的myid的内容修改为2"><a href="#6-将kafka2-data-zk目录下的myid的内容修改为2" class="headerlink" title="6.将kafka2/data/zk目录下的myid的内容修改为2"></a>6.将<code>kafka2/data/zk</code>目录下的<code>myid</code>的内容修改为2</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka2/data/zk</span><br><span class="line">$ vi myid</span><br></pre></td></tr></table></figure>
<p>同理，将将<code>kafka3/data/zk</code>目录下的<code>myid</code>的内容修改为3<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3/data/zk</span><br><span class="line">$ vi myid</span><br></pre></td></tr></table></figure></p>
<h3 id="7-修改kafka2的配置文件"><a href="#7-修改kafka2的配置文件" class="headerlink" title="7.修改kafka2的配置文件"></a>7.修改<code>kafka2</code>的配置文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka2/config</span><br><span class="line">$ vi zookeeper.properties</span><br></pre></td></tr></table></figure>
<p>仅修改两处地方即可，要修改的地方如下：</p>
<pre><code>dataDir=/home/hewentian/ProjectD/kafkaCluster/kafka2/data/zk  # 这里是数据保存的位置
clientPort=2182                                               # 这台服务器的端口为2182
</code></pre><p>同理，修改<code>kafka3</code>的配置文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3/config</span><br><span class="line">$ vi zookeeper.properties</span><br></pre></td></tr></table></figure></p>
<p>仅修改两处地方即可，要修改的地方如下：</p>
<pre><code>dataDir=/home/hewentian/ProjectD/kafkaCluster/kafka3/data/zk  # 这里是数据保存的位置
clientPort=2183                                               # 这台服务器的端口为2183
</code></pre><h3 id="8-到目前为此，我们已经将3台zookeeper服务器都配置好了。接下来，我们要将他们都启动"><a href="#8-到目前为此，我们已经将3台zookeeper服务器都配置好了。接下来，我们要将他们都启动" class="headerlink" title="8.到目前为此，我们已经将3台zookeeper服务器都配置好了。接下来，我们要将他们都启动"></a>8.到目前为此，我们已经将3台<code>zookeeper</code>服务器都配置好了。接下来，我们要将他们都启动</h3><p>启动kafka1的zookeeper服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka1</span><br><span class="line">$ nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &gt; logs/zookeeper.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<p>启动kafka2的zookeeper服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka2</span><br><span class="line">$ mkdir logs</span><br><span class="line">$ nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &gt; logs/zookeeper.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<p>启动kafka3的zookeeper服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3</span><br><span class="line">$ mkdir logs</span><br><span class="line">$ nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &gt; logs/zookeeper.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<h3 id="9-当三台服务器都启动好了，我们分别连到三台zookeeper服务器："><a href="#9-当三台服务器都启动好了，我们分别连到三台zookeeper服务器：" class="headerlink" title="9.当三台服务器都启动好了，我们分别连到三台zookeeper服务器："></a>9.当三台服务器都启动好了，我们分别连到三台zookeeper服务器：</h3><p>连接到kafka1的zookeeper服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka1</span><br><span class="line">$ ./bin/zookeeper-shell.sh 127.0.0.1:2181</span><br></pre></td></tr></table></figure></p>
<p>连接到kafka2的zookeeper服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka2</span><br><span class="line">$ ./bin/zookeeper-shell.sh 127.0.0.1:2182</span><br></pre></td></tr></table></figure></p>
<p>连接到kafka3的zookeeper服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3</span><br><span class="line">$ ./bin/zookeeper-shell.sh 127.0.0.1:2183</span><br></pre></td></tr></table></figure></p>
<p>可以通过查看<code>logs/zookeeper.log</code>文件，如果没有报错就说明zookeeper集群启动成功。</p>
<p>这样你在<code>kafka1</code>中的<code>zookeeper</code>所作的修改，都会同步到<code>kafka2</code>, <code>kafka3</code>。<br>例如你在kafka1的zookeeper服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ create /zk_test_cluster my_data_cluster</span><br></pre></td></tr></table></figure></p>
<p>你在kafka2, kafka3的zookeeper客户端用<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls /</span><br></pre></td></tr></table></figure></p>
<p>都会看到节点zk_test_cluster</p>
<p>至此，zookeeper集群部署结束。</p>
<h3 id="10-搭建kafka集群"><a href="#10-搭建kafka集群" class="headerlink" title="10.搭建kafka集群"></a>10.搭建kafka集群</h3><p>配置<code>kafka1</code>服务器：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka1</span><br><span class="line">$ vi config/server.properties</span><br><span class="line"></span><br><span class="line">broker.id=1                           <span class="comment"># 这里设置为1，另外两台分别设置为2、3</span></span><br><span class="line"></span><br><span class="line">listeners=PLAINTEXT://127.0.0.1:9092  <span class="comment"># IP地址和端口，这里使用默认的 9092，另外两台分别使用9093、9094</span></span><br><span class="line"></span><br><span class="line">log.dirs=/home/hewentian/ProjectD/kafkaCluster/kafka1/data/kafka</span><br><span class="line"></span><br><span class="line">zookeeper.connect=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183</span><br></pre></td></tr></table></figure></p>
<p>配置<code>kafka2</code>服务器：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka2</span><br><span class="line">$ vi config/server.properties</span><br><span class="line"></span><br><span class="line">broker.id=2</span><br><span class="line"></span><br><span class="line">listeners=PLAINTEXT://127.0.0.1:9093</span><br><span class="line"></span><br><span class="line">log.dirs=/home/hewentian/ProjectD/kafkaCluster/kafka2/data/kafka</span><br><span class="line"></span><br><span class="line">zookeeper.connect=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183</span><br></pre></td></tr></table></figure></p>
<p>配置<code>kafka3</code>服务器：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3</span><br><span class="line">$ vi config/server.properties</span><br><span class="line"></span><br><span class="line">broker.id=3</span><br><span class="line"></span><br><span class="line">listeners=PLAINTEXT://127.0.0.1:9094</span><br><span class="line"></span><br><span class="line">log.dirs=/home/hewentian/ProjectD/kafkaCluster/kafka3/data/kafka</span><br><span class="line"></span><br><span class="line">zookeeper.connect=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183</span><br></pre></td></tr></table></figure></p>
<h3 id="11-启动三台kafka服务器"><a href="#11-启动三台kafka服务器" class="headerlink" title="11.启动三台kafka服务器"></a>11.启动三台kafka服务器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka1</span><br><span class="line">$ ./bin/kafka-server-start.sh -daemon /home/hewentian/ProjectD/kafkaCluster/kafka1/config/server.properties</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka2</span><br><span class="line">$ ./bin/kafka-server-start.sh -daemon /home/hewentian/ProjectD/kafkaCluster/kafka2/config/server.properties</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3</span><br><span class="line">$ ./bin/kafka-server-start.sh -daemon /home/hewentian/ProjectD/kafkaCluster/kafka3/config/server.properties</span><br></pre></td></tr></table></figure>
<p>分别从三台kafka服务器中查看启动日志<code>logs/server.log</code>，如果没报错，并且看到如下输出，则启动成功：</p>
<pre><code># kafka1 的输出
[2018-10-27 15:48:54,890] INFO Kafka version : 2.0.0 (org.apache.kafka.common.utils.AppInfoParser)
[2018-10-27 15:48:54,890] INFO Kafka commitId : 3402a8361b734732 (org.apache.kafka.common.utils.AppInfoParser)
[2018-10-27 15:48:54,895] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)

# kafka2 的输出
[2018-10-27 15:49:22,694] INFO Kafka version : 2.0.0 (org.apache.kafka.common.utils.AppInfoParser)
[2018-10-27 15:49:22,694] INFO Kafka commitId : 3402a8361b734732 (org.apache.kafka.common.utils.AppInfoParser)
[2018-10-27 15:49:22,697] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)

# kafka3 的输出
[2018-10-27 15:49:41,746] INFO Kafka version : 2.0.0 (org.apache.kafka.common.utils.AppInfoParser)
[2018-10-27 15:49:41,746] INFO Kafka commitId : 3402a8361b734732 (org.apache.kafka.common.utils.AppInfoParser)
[2018-10-27 15:49:41,749] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
</code></pre><p>至此，kafka集群搭建成功。下面，我们简单的试用一下。</p>
<h3 id="12-创建topic"><a href="#12-创建topic" class="headerlink" title="12.创建topic"></a>12.创建topic</h3><p>在任意一台kafka服务器上面创建topic，例如在kafka1上面创建一个名为 my-replicated-topic 的 topic，指定 1 个分区，3 个副本：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka1</span><br><span class="line">$ ./bin/kafka-topics.sh --create --zookeeper 127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183 --replication-factor 3 --partitions 1 --topic my-replicated-topic</span><br><span class="line"></span><br><span class="line">Created topic <span class="string">"my-replicated-topic"</span>.</span><br></pre></td></tr></table></figure></p>
<p>上面的参数<code>--zookeeper</code>是集群列表，可以指定所有节点，也可以指定为部分列表。</p>
<p>查看topic的情况：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka1</span><br><span class="line">$ ./bin/kafka-topics.sh --describe --zookeeper 127.0.0.1:2181 --topic my-replicated-topic</span><br><span class="line"></span><br><span class="line">Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:</span><br><span class="line">	Topic: my-replicated-topic	Partition: 0	Leader: 3	Replicas: 3,2,1	Isr: 3,2,1</span><br></pre></td></tr></table></figure></p>
<h3 id="13-发送消息"><a href="#13-发送消息" class="headerlink" title="13.发送消息"></a>13.发送消息</h3><p>往我们刚才创建的toipc中发送消息，在任意一台kafka上面都可以的，我们在kafka2上面执行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka2</span><br><span class="line">$ ./bin/kafka-console-producer.sh --broker-list 127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094 --topic my-replicated-topic</span><br><span class="line">&gt;</span><br><span class="line">&gt;my <span class="built_in">test</span> message 1</span><br><span class="line">&gt;my <span class="built_in">test</span> message 2</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="14-消费消息"><a href="#14-消费消息" class="headerlink" title="14.消费消息"></a>14.消费消息</h3><p>将我们刚刚发送的消息消费掉，我们从kafka3上面执行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3</span><br><span class="line">$ ./bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094 --from-beginning --topic my-replicated-topic</span><br><span class="line"></span><br><span class="line">my <span class="built_in">test</span> message 1</span><br><span class="line">my <span class="built_in">test</span> message 2</span><br></pre></td></tr></table></figure></p>
<p>我们在生产者中发送消息，在消费者中就能实时的看到消息。</p>
<h3 id="15-容错测试"><a href="#15-容错测试" class="headerlink" title="15.容错测试"></a>15.容错测试</h3><p>从上面可知my-replicated-topic的leader为3，那我们将broker.id=3的进程杀掉：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3</span><br><span class="line">$ ps -ef | grep kafka3/config/server.properties</span><br><span class="line">hewenti+ 22018  1897  5 17:19 pts/23   00:00:16 /usr/<span class="built_in">local</span>/java/jdk1.8.0_102/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[中间省略部分]</span><br><span class="line"></span><br><span class="line">-0.10.jar:/home/hewentian/ProjectD/kafkaCluster/kafka3/bin/../libs/zookeeper-3.4.13.jar kafka.Kafka /home/hewentian/ProjectD/kafkaCluster/kafka3/config/server.properties</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">kill</span> -9 22018       <span class="comment"># 单机环境下不能通过执行： ./bin/kafka-server-stop.sh 来杀掉当前目录下的kafka，它会杀掉全部kafka</span></span><br></pre></td></tr></table></figure></p>
<p>再查看my-replicated-topic的情况：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3</span><br><span class="line">$ ./bin/kafka-topics.sh --describe --zookeeper 127.0.0.1:2181 --topic my-replicated-topic</span><br><span class="line">Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:</span><br><span class="line">	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 3,2,1	Isr: 1</span><br></pre></td></tr></table></figure></p>
<p>由上面可见，leader已经变为1。并且，生产消息和消费消息一样可用，不受影响：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka2</span><br><span class="line">$ ./bin/kafka-console-producer.sh --broker-list 127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094 --topic my-replicated-topic</span><br><span class="line">&gt;</span><br><span class="line">&gt;my <span class="built_in">test</span> message 1</span><br><span class="line">&gt;my <span class="built_in">test</span> message 2</span><br><span class="line">&gt;</span><br><span class="line">&gt; Tim Ho</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafkaCluster/kafka3</span><br><span class="line">$ ./bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094 --from-beginning --topic my-replicated-topic</span><br><span class="line"></span><br><span class="line">my <span class="built_in">test</span> message 1</span><br><span class="line">my <span class="built_in">test</span> message 2</span><br><span class="line"></span><br><span class="line">Tim Ho</span><br></pre></td></tr></table></figure>
<p>未完，待续……</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/10/27/kafka-cluster/" data-id="cjogzpsl30014vv2i208r1jxk" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kafka-standalone" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/24/kafka-standalone/" class="article-date">
  <time datetime="2018-10-24T00:32:40.000Z" itemprop="datePublished">2018-10-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/24/kafka-standalone/">kafka 单节点安装</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文将说下<code>kafka</code>的单节点安装，我的机器为<code>Ubuntu 16.04 LTS</code>，下面的安装过程参考：<br><a href="http://kafka.apache.org/quickstart" target="_blank" rel="noopener">http://kafka.apache.org/quickstart</a></p>
<h3 id="第一步：我们要将kafka安装包下载回来"><a href="#第一步：我们要将kafka安装包下载回来" class="headerlink" title="第一步：我们要将kafka安装包下载回来"></a>第一步：我们要将<code>kafka</code>安装包下载回来</h3><p>截止本文写时，它的最新版本为<code>2.0.0</code>，可以在它的<a href="https://www.apache.org/dist/kafka/2.0.0/kafka_2.12-2.0.0.tgz" target="_blank" rel="noopener">官网</a>下载。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget https://www.apache.org/dist/kafka/2.0.0/kafka_2.12-2.0.0.tgz</span><br><span class="line">$ wget https://www.apache.org/dist/kafka/2.0.0/kafka_2.12-2.0.0.tgz.sha512</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性，在下载的时候要将 SHA512 文件也下载回来</span><br><span class="line">$ sha512sum -c kafka_2.12-2.0.0.tgz.sha512</span><br><span class="line">kafka_2.12-2.0.0.tgz: OK</span><br><span class="line"></span><br><span class="line">$ tar xzf kafka_2.12-2.0.0.tgz</span><br></pre></td></tr></table></figure></p>
<h3 id="第二步：启动服务器"><a href="#第二步：启动服务器" class="headerlink" title="第二步：启动服务器"></a>第二步：启动服务器</h3><p>kafka需要用到zookeeper，所以必须首先启动zookeeper。在高版本的kafka发行包中，已经内置zookeeper，我们直接使用即可。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafka_2.12-2.0.0/</span><br><span class="line">$ ./bin/zookeeper-server-start.sh config/zookeeper.properties</span><br></pre></td></tr></table></figure></p>
<p>启动成功后，会看到如下输出：</p>
<pre><code>[2018-10-24 09:14:29,072] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,072] INFO Server environment:java.compiler=&lt;NA&gt; (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,072] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,072] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,072] INFO Server environment:os.version=4.13.0-32-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,072] INFO Server environment:user.name=hewentian (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,073] INFO Server environment:user.home=/home/hewentian (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,073] INFO Server environment:user.dir=/home/hewentian/ProjectD/kafka_2.12-2.0.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,091] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,091] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,091] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-10-24 09:14:29,111] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2018-10-24 09:14:29,121] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
</code></pre><p>接着，打开另外一个终端，启动kafka服务器：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafka_2.12-2.0.0/</span><br><span class="line">$ ./bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure></p>
<p>启动成功后，会看到如下输出：</p>
<pre><code>[2018-10-24 11:01:45,462] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2018-10-24 11:01:45,494] INFO Kafka version : 2.0.0 (org.apache.kafka.common.utils.AppInfoParser)
[2018-10-24 11:01:45,494] INFO Kafka commitId : 3402a8361b734732 (org.apache.kafka.common.utils.AppInfoParser)
[2018-10-24 11:01:45,497] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
</code></pre><h3 id="第三步：创建topic"><a href="#第三步：创建topic" class="headerlink" title="第三步：创建topic"></a>第三步：创建topic</h3><p>创建一个名字叫<code>test</code>的topic，只有一个分区和一个副本，打开另外一个终端：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafka_2.12-2.0.0/</span><br><span class="line">$ ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic <span class="built_in">test</span></span><br><span class="line">Created topic <span class="string">"test"</span>.</span><br><span class="line"></span><br><span class="line">查看所有创建的topic</span><br><span class="line">$ ./bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br><span class="line"><span class="built_in">test</span></span><br></pre></td></tr></table></figure></p>
<h3 id="第四步：往topic发送消息"><a href="#第四步：往topic发送消息" class="headerlink" title="第四步：往topic发送消息"></a>第四步：往topic发送消息</h3><p>kafka自带一个命令行的客户端，用于从文件中或者标准输入中读取消息并且发送到kafka集群，默认每一行会被作为一条消息发送：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafka_2.12-2.0.0/</span><br><span class="line">$ ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic <span class="built_in">test</span></span><br><span class="line">&gt;This is a message</span><br><span class="line">&gt;This is another message</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="第五步：消费topic中的消息"><a href="#第五步：消费topic中的消息" class="headerlink" title="第五步：消费topic中的消息"></a>第五步：消费topic中的消息</h3><p>kafka同样自带一个命令行的消费者，它会将消息输出到标准输出：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kafka_2.12-2.0.0/</span><br><span class="line">$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="built_in">test</span> --from-beginning</span><br><span class="line">This is a message</span><br><span class="line">This is another message</span><br></pre></td></tr></table></figure></p>
<p>这样，一个简单的单节点<code>kafka</code>服务器就搭建完成了，接下来我们将尝试搭建多节点的集群。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/10/24/kafka-standalone/" data-id="cjogzpsln001avv2i4fy9bief" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-jenkins-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/05/jenkins-install/" class="article-date">
  <time datetime="2018-10-05T04:02:47.000Z" itemprop="datePublished">2018-10-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/other/">other</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/05/jenkins-install/">jenkins 学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本篇将说说jenkins的使用，通过阅读本POST，你将拥有一台属于自已的jenkins服务器。</p>
<p>首先，我们要将<code>jenkins</code>的安装包下载回来，可以在它的<a href="http://mirrors.jenkins.io/war-stable/latest/" target="_blank" rel="noopener">官网</a>下载最新稳定版：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war</span><br><span class="line">$ wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war.sha256</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性</span><br><span class="line">$ sha256sum -c jenkins.war.sha256 </span><br><span class="line">jenkins.war: OK</span><br></pre></td></tr></table></figure>
<p>我们将它安装在当前目录(<code>/home/hewentian/ProjectD</code>)下，在当前目录下创建一个jenkins目录，用作<code>JENKINS_HOME</code>目录，我们将相关命令放到一个脚本<code>start_jenkins.sh</code>中：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD</span><br><span class="line">$ touch start_jenkins.sh</span><br><span class="line">$ vi start_jenkins.sh</span><br></pre></td></tr></table></figure></p>
<p>其中<code>start_jenkins.sh</code>脚本的内容如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">JENKINS_HOME=/home/hewentian/ProjectD/jenkins</span><br><span class="line">JENKINS_WAR=/home/hewentian/ProjectD/jenkins.war</span><br><span class="line">LOG_ROOT=<span class="variable">$JENKINS_HOME</span>/logs</span><br><span class="line">LOG_FILE=<span class="variable">$LOG_ROOT</span>/jenkins.log</span><br><span class="line">WEB_ROOT=<span class="variable">$JENKINS_HOME</span>/war</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Starting Jenkins ..."</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"JENKINS_HOME: <span class="variable">$JENKINS_HOME</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"JENKINS_WAR: <span class="variable">$JENKINS_WAR</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"LOG_FILE: <span class="variable">$LOG_FILE</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"WEB_ROOT: <span class="variable">$WEB_ROOT</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$JENKINS_HOME</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"creating: <span class="variable">$JENKINS_HOME</span>"</span></span><br><span class="line">    mkdir <span class="variable">$JENKINS_HOME</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$LOG_ROOT</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"creating: <span class="variable">$LOG_ROOT</span>"</span></span><br><span class="line">    mkdir <span class="variable">$LOG_ROOT</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -e <span class="variable">$LOG_FILE</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"creating: <span class="variable">$LOG_FILE</span>"</span></span><br><span class="line">    touch <span class="variable">$LOG_FILE</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$WEB_ROOT</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"creating: <span class="variable">$WEB_ROOT</span>"</span></span><br><span class="line">    mkdir <span class="variable">$WEB_ROOT</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">java -Xms1024m -Xmx1024m -Djava.awt.headless=<span class="literal">true</span> -DJENKINS_HOME=<span class="variable">$JENKINS_HOME</span> -jar <span class="variable">$JENKINS_WAR</span> --logfile=<span class="variable">$LOG_FILE</span> --webroot=<span class="variable">$WEB_ROOT</span> --httpPort=8080 --daemon &gt;&gt; <span class="variable">$LOG_FILE</span></span><br><span class="line"></span><br><span class="line">tail -f <span class="variable">$LOG_FILE</span></span><br></pre></td></tr></table></figure></p>
<p>启动jenkins：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ chmod +x start_jenkins.sh</span><br><span class="line">$ . start_jenkins.sh</span><br></pre></td></tr></table></figure></p>
<p>如果你看到如下输出：</p>
<pre><code>Starting Jenkins ...
JENKINS_HOME: /home/hewentian/ProjectD/jenkins
JENKINS_WAR: /home/hewentian/ProjectD/jenkins.war
LOG_FILE: /home/hewentian/ProjectD/jenkins/logs/jenkins.log
WEB_ROOT: /home/hewentian/ProjectD/jenkins/war
creating: /home/hewentian/ProjectD/jenkins
creating: /home/hewentian/ProjectD/jenkins/logs
creating: /home/hewentian/ProjectD/jenkins/logs/jenkins.log
creating: /home/hewentian/ProjectD/jenkins/war
Forking into background to run as a daemon.
Running from: /home/hewentian/ProjectD/jenkins.war
Oct 06, 2018 10:48:18 AM org.eclipse.jetty.util.log.Log initialized
INFO: Logging initialized @780ms to org.eclipse.jetty.util.log.JavaUtilLog
Oct 06, 2018 10:48:18 AM winstone.Logger logInternal
.
.
. 中间省略部分日志
.
Oct 06, 2018 10:48:29 AM jenkins.install.SetupWizard init
INFO: 

*************************************************************
*************************************************************
*************************************************************

Jenkins initial setup is required. An admin user has been created and a password generated.
Please use the following password to proceed to installation:

02b24053bc4844f4a348fdbbbf65c347

This may also be found at: /home/hewentian/ProjectD/jenkins/secrets/initialAdminPassword

*************************************************************
*************************************************************
*************************************************************

Oct 06, 2018 10:48:36 AM hudson.model.UpdateSite updateData
INFO: Obtained the latest update center data file for UpdateSource default
Oct 06, 2018 10:48:37 AM hudson.model.UpdateSite updateData
INFO: Obtained the latest update center data file for UpdateSource default
Oct 06, 2018 10:48:37 AM jenkins.InitReactorRunner$1 onAttained
INFO: Completed initialization
Oct 06, 2018 10:48:37 AM hudson.WebAppMain$3 run
INFO: Jenkins is fully up and running
Oct 06, 2018 10:48:37 AM hudson.model.DownloadService$Downloadable load
INFO: Obtained the updated data file for hudson.tasks.Maven.MavenInstaller
Oct 06, 2018 10:48:37 AM hudson.model.AsyncPeriodicWork$1 run
INFO: Finished Download metadata. 10,126 ms
</code></pre><p>则证明启动成功，我们按上面的提示打开浏览器，输入：<br><a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a></p>
<p>你将会见到如下界面：<br><img src="/img/jenkins-1.png" alt="" title="jenkins初次启动界面"></p>
<p>将上面日志中的密码输入到上述界面，并点击<code>[Continue]</code>按钮，将出现下图界面：<br><img src="/img/jenkins-2.png" alt="" title="jenkins安装插件界面"></p>
<p>为简单起见，选择<code>Install suggested plugins</code>安装即可，安装进度如下：<br><img src="/img/jenkins-3.png" alt="" title="jenkins安装插件界面"></p>
<p>接下来是设置admin用户和密码：<br>Username: hewentian<br>Password: abc123</p>
<p><img src="/img/jenkins-4.png" alt="" title="jenkins设置admin用户"></p>
<p>点击<code>[Save and Continue]</code>，并在接下来的界面点击<code>[Save and Finish]</code>完成设置。<br><img src="/img/jenkins-5.png" alt="" title="jenkins最终界面"></p>
<h3 id="下面进行简单的配置"><a href="#下面进行简单的配置" class="headerlink" title="下面进行简单的配置"></a>下面进行简单的配置</h3><p>按下图所示设置JDK、Maven：<code>[Manage Jenkins]-&gt;[Global Tool Configuration]</code>：<br><img src="/img/jenkins-6.png" alt="" title="设置"><br><img src="/img/jenkins-7.png" alt="" title="设置"></p>
<h3 id="下面安装插件"><a href="#下面安装插件" class="headerlink" title="下面安装插件"></a>下面安装插件</h3><p><code>[Manage Jenkins]-&gt;[Manage Plugins]</code><br>安装<code>Maven Integration</code>插件，如下图，直接点击<code>Install wthout restart</code>，该插件是用于建立maven job<br><img src="/img/jenkins-8.png" alt="" title="安装maven插件"></p>
<p>安装<code>Deploy to container</code>插件，用于将构建好的应用部署到容器中：<br><img src="/img/jenkins-9.png" alt="" title="安装Deploy to container插件"></p>
<h3 id="下面演示构建项目"><a href="#下面演示构建项目" class="headerlink" title="下面演示构建项目"></a>下面演示构建项目</h3><h4 id="示例A、构建一个从gitHub中拉取原码的maven项目"><a href="#示例A、构建一个从gitHub中拉取原码的maven项目" class="headerlink" title="示例A、构建一个从gitHub中拉取原码的maven项目"></a>示例A、构建一个从gitHub中拉取原码的maven项目</h4><p><code>[New Item]</code>-&gt;选择<code>[Maven project]</code>，并在<code>[Enter an item name]</code>中输入mvn-test，然后点击<code>[ok]</code>，如下图：<br><img src="/img/jenkins-10.png" alt="" title="构建一个从gitHub中拉取原码的maven项目"></p>
<p>在弹出的界面中选中<code>[Discard old builds]</code>并将<code>Max of builds to keep</code>设为10，然后设置源码仓库，如下所示：<br><img src="/img/jenkins-11.png" alt=""></p>
<p><strong> 注意： </strong> 如果我们的仓库中包含有多个项目，而我们此处要构建的只是其中一个，则我们需要指定构建哪一个：<code>Additional Behaviours -&gt; Add -&gt; Sparse Checkout paths</code>，在<code>Path</code>处填入: <code>/{repository_name}/{need_to_build_project}/**</code></p>
<p>例如：<br>Repository URL: <code>https://github.com/jenkins-docs/simple-java-maven-app.git</code><br>Path: <code>/simple-java-maven-app/my-app/**</code><br>如果是这种方式，则下面的Root POM也要修改成对应的项目:<br>Root POM: <code>simple-java-maven-app/my-app/pom.xml</code><br>上面的Path开头是有<code>/</code>的，而Root POM开头是没有<code>/</code>的。</p>
<p>设置Build的<code>Goals and options</code>为<code>clean install</code>，如下：<br><img src="/img/jenkins-12.png" alt=""></p>
<p>其他设置保持默认，点击<code>[Save]</code>，在弹出的界面点击<code>[Build Now]</code>，然后再点击下方构建历史中正在构建的任务的<code>[Console Output]</code>。<br><img src="/img/jenkins-13.png" alt=""></p>
<p><img src="/img/jenkins-14.png" alt=""><br><img src="/img/jenkins-15.png" alt=""></p>
<p>如上图所示，构建成功了。切换到上图中的目录中查看目标文件，并运行它：<br><img src="/img/jenkins-16.png" alt=""></p>
<p>这样，一个简单的maven项目就构建完成了。</p>
<h4 id="示例B、构建一个从gitHub中拉取原码的maven-web项目，并部署到运行中的tomcat"><a href="#示例B、构建一个从gitHub中拉取原码的maven-web项目，并部署到运行中的tomcat" class="headerlink" title="示例B、构建一个从gitHub中拉取原码的maven web项目，并部署到运行中的tomcat"></a>示例B、构建一个从gitHub中拉取原码的maven web项目，并部署到运行中的tomcat</h4><p>首先，我们创建一个最简单的maven web项目，并推到：<br><a href="https://github.com/hewentian/web-test">https://github.com/hewentian/web-test</a><br>web-test项目只有三个文件：</p>
<pre><code>pom.xml
src/main/webapp/WEB-INF/web.xml
src/main/webapp/index.jsp
</code></pre><p><code>pom.xml</code>文件内容如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.hewentian<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>web-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">packaging</span>&gt;</span>war<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>web-test Maven Webapp<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.apache.org<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">finalName</span>&gt;</span>web-test<span class="tag">&lt;/<span class="name">finalName</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><code>src/main/webapp/WEB-INF/web.xml</code>文件内容如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE web-app PUBLIC</span></span><br><span class="line"><span class="meta"> "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN"</span></span><br><span class="line"><span class="meta"> "http://java.sun.com/dtd/web-app_2_3.dtd" &gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">web-app</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">display-name</span>&gt;</span>Archetype Created Web Application<span class="tag">&lt;/<span class="name">display-name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><code>src/main/webapp/index.jsp</code>文件内容如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">	&lt;body&gt;</span><br><span class="line">		&lt;h2&gt;Hello World!&lt;/h2&gt;</span><br><span class="line">	&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<p>接着，我们准备一台tomcat，我已经准备好了一台，位于：</p>
<pre><code>/home/hewentian/ProjectD/apache-tomcat-8.0.47
</code></pre><p>因为jenkins使用了<code>8080</code>端口，所以tomcat不能使用默认的<code>8080</code>端口，我们将其修改为<code>8867</code>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/apache-tomcat-8.0.47/conf</span><br><span class="line">$ vi server.xml</span><br><span class="line"></span><br><span class="line">只修改此处即可</span><br><span class="line">&lt;Connector port=<span class="string">"8867"</span> protocol=<span class="string">"HTTP/1.1"</span> connectionTimeout=<span class="string">"20000"</span> redirectPort=<span class="string">"8443"</span> /&gt;</span><br></pre></td></tr></table></figure></p>
<p>配置tomcat的管理员帐号：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/apache-tomcat-8.0.47/conf</span><br><span class="line">$ vi tomcat-users.xml</span><br><span class="line"></span><br><span class="line">在&lt;tomcat-users&gt;节点里添加如下内容：</span><br><span class="line"></span><br><span class="line">&lt;role rolename=<span class="string">"manager-gui"</span>/&gt;</span><br><span class="line">&lt;role rolename=<span class="string">"manager-script"</span>/&gt;</span><br><span class="line">&lt;role rolename=<span class="string">"manager-jmx"</span>/&gt;</span><br><span class="line">&lt;role rolename=<span class="string">"manager-status"</span>/&gt;</span><br><span class="line"></span><br><span class="line">&lt;user username=<span class="string">"hwt"</span> password=<span class="string">"pwd123"</span> roles=<span class="string">"manager-gui,manager-script,manager-jmx,manager-status"</span>/&gt;</span><br></pre></td></tr></table></figure></p>
<p>其中的<code>username=&quot;hwt&quot; password=&quot;pwd123&quot;</code>是用于登录Tomcat用的，下面会用到，重启tomcat。</p>
<p>回到jenkins，我们新建一个Item，命名为web-app-test：<br><img src="/img/jenkins-17.png" alt=""><br><img src="/img/jenkins-18.png" alt=""></p>
<p>配置代码仓库，如下图。点击<code>Credentials</code>右边的<code>Add-&gt;jenkins</code><br><img src="/img/jenkins-19.png" alt=""></p>
<p>在弹出的对话框中，选择<code>SSH Username with private key</code>，将<code>~/.ssh/id_rsa</code>文件的内容复制到Key中，点<code>Add</code>：<br><img src="/img/jenkins-20.png" alt=""></p>
<p>在配置代码仓库中，选择刚才创建的<code>Credentials</code>：<br><img src="/img/jenkins-21.png" alt=""></p>
<p>配置构建触发器：<br><img src="/img/jenkins-22.png" alt=""></p>
<p>说明：</p>
<ol>
<li>Build whenever a SNAPSHOT dependency is built：在构建的时候，会根据pom.xml文件的继承关系构建发生一个构建引起其他构建的；</li>
<li>Poll SCM：这是CI系统中常见的选项。当您选择此选项，您可以指定一个定时作业表达式来定义Jenkins每隔多久检查一下您源代码仓库的变化。如果发现变化，就执行一次构建。例如，表达式中填写0,15,30,45 <em> </em> <em> </em>将使Jenkins每隔15分钟就检查一次您源码仓库的变化；</li>
<li>Build periodically：此选项仅仅通知Jenkins按指定的频率对项目进行构建，而不管SCM是否有变化。如果想在这个Job中运行一些测试用例的话，它就很有帮助。</li>
</ol>
<p>配置构建设置：<br><img src="/img/jenkins-23.png" alt=""></p>
<p>接着我们试着点击<code>Build Now</code>试下能否成功构建：<br><img src="/img/jenkins-24.png" alt=""></p>
<p>当你看到如下输出时，证明构建成功：<br><img src="/img/jenkins-25.png" alt=""></p>
<p>接着我们配置部署到tomcat，回到web-app-test的jenkins配置，在<code>Add post-build action</code>中选择<code>Deploy war/ear to a container</code>，如下图：<br><img src="/img/jenkins-26.png" alt=""></p>
<p>在<code>Credentials</code>右则点击<code>Add-&gt;Jenkins</code>，并在弹出的对话框中输入上面在tomcat中配置的用户名：<br><img src="/img/jenkins-27.png" alt=""></p>
<p>说明：</p>
<ol>
<li>首先tomcat是启动的，并且Tomcat中没有部署web-test.war；</li>
<li>WAR/EAR files：war文件的存放位置，如：target/web-test.war 注意：相对路径，target前是没有/的；</li>
<li>Context path：访问时需要输入的内容，如wt访问时如下：<a href="http://127.0.0.1:8867/wt/" target="_blank" rel="noopener">http://127.0.0.1:8867/wt/</a>，如果为空，默认是war包的名字；</li>
<li>Container：选择你的web容器，如tomca 8.x；</li>
<li>Credentials: 在右边的下拉页面中选择访问Tomcat的用户名、密码，如果没有，则点【Add】；</li>
<li>Tomcat URL：填入你Tomcat的访问地址，如：<a href="http://127.0.0.1:8867/；" target="_blank" rel="noopener">http://127.0.0.1:8867/；</a></li>
<li>svn、git、tomcat的用户名和密码设置了是没有办法在web界面修改的。如果要修改则先去Jenkins目录删除hudson.scm.SubversionSCM.xml文件，或者在jenkins用户页中删掉该用户，虽然jenkins页面提供修改方法，但是，无效。</li>
</ol>
<p>接着我们点击<code>Build Now</code>开始构建：<br><img src="/img/jenkins-28.png" alt=""></p>
<p>如果你看到上面输出，则证明构建和部署成功，可以打开浏览器查看：<br><img src="/img/jenkins-29.png" alt=""></p>
<p>到此，大功告成。</p>
<h4 id="示例C、将示例A产生的JAR包部署到远程机器上面运行"><a href="#示例C、将示例A产生的JAR包部署到远程机器上面运行" class="headerlink" title="示例C、将示例A产生的JAR包部署到远程机器上面运行"></a>示例C、将示例A产生的JAR包部署到远程机器上面运行</h4><p>我们回到示例A的jenkins配置，在Post Steps下选择<code>Run only if build succeeds</code>，点<code>Add post-build step</code>并选择<code>Execute shell</code>，在Command中填入如下脚本，此脚本由我同事<code>严忠思</code>编写，我稍作修改：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.定义变量</span></span><br><span class="line"><span class="comment"># SSH 端口</span></span><br><span class="line"><span class="built_in">export</span> SSH_PORT=<span class="string">"12022"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行 jar 包的机器,多个IP以空格分隔，如: 192.168.30.241 192.168.30.242</span></span><br><span class="line"><span class="built_in">export</span> SSH_IP_LIST=<span class="string">"192.168.30.241"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行 jar 的用户</span></span><br><span class="line"><span class="built_in">export</span> USERNAME=<span class="string">"root"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 环境 dev,test,gray,prod</span></span><br><span class="line"><span class="built_in">export</span> RUN_SERVER=<span class="string">"dev"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 远程存放 jar 包文件路径,注这个路径要先手动创建, mkdir -p /www/web/my-app &amp;&amp; chown root.root /www/web/my-app</span></span><br><span class="line"><span class="built_in">export</span> REMOTE_JAR_DIR=<span class="string">"/www/web/my-app/<span class="variable">$&#123;RUN_SERVER&#125;</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Jenkins (-DJENKINS_HOME)用 maven 编译打包程序的路径与文件</span></span><br><span class="line"><span class="built_in">export</span> JENKINS_JAR_FILE=<span class="string">"/home/hewentian/ProjectD/jenkins/workspace/mvn-test/target/my-app-1.0-SNAPSHOT.jar"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#jar 打包文件名</span></span><br><span class="line"><span class="built_in">export</span> JAR_FILE=<span class="string">"my-app-1.0-SNAPSHOT.jar"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行 JAR 的端口，我这里并不使用这个端口号，故可不填</span></span><br><span class="line"><span class="built_in">export</span> JAR_PORT=<span class="string">"8802"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志路径</span></span><br><span class="line"><span class="built_in">export</span> LOG_PATH=<span class="string">"/www/logs/my-app"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#jvm参数</span></span><br><span class="line"><span class="built_in">export</span> JAR_JAVA_OPTS=<span class="string">"-XX:-UseGCOverheadLimit -Xmx1024m"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># jar 运行命令</span></span><br><span class="line"><span class="built_in">export</span> JAR_COMMOND=<span class="string">"nohup java <span class="variable">$&#123;JAR_JAVA_OPTS&#125;</span> \</span></span><br><span class="line"><span class="string">-jar <span class="variable">$&#123;REMOTE_JAR_DIR&#125;</span>/<span class="variable">$&#123;JAR_FILE&#125;</span> \</span></span><br><span class="line"><span class="string">--spring.cloud.config.profile=<span class="variable">$&#123;RUN_SERVER&#125;</span> \</span></span><br><span class="line"><span class="string">--server.port=<span class="variable">$&#123;JAR_PORT&#125;</span> \</span></span><br><span class="line"><span class="string">--logging.path=<span class="variable">$&#123;LOG_PATH&#125;</span> \</span></span><br><span class="line"><span class="string">&gt; <span class="variable">$&#123;LOG_PATH&#125;</span>/my-app.log &amp;"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待时间，如果不配置，则脚本默认为 40 秒</span></span><br><span class="line"><span class="built_in">export</span> SLEEP_SEC=20</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.主程序</span></span><br><span class="line">/bin/bash -x /home/hewentian/ProjectD/jenkins/script/jar.sh</span><br></pre></td></tr></table></figure></p>
<p>在我的本机执行如下命令，创建存放脚本的目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/jenkins</span><br><span class="line">$ mkdir script</span><br><span class="line">$ <span class="built_in">cd</span> script</span><br><span class="line">$ touch jar.sh</span><br><span class="line">$ chmod +x jar.sh</span><br></pre></td></tr></table></figure></p>
<p>在jar.sh中输入如下脚本，此脚本同样由我的同事<code>严忠思</code>编写：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/env sh</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /etc/profile &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"-------------------- start print env var --------------------"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"SSH_PORT: <span class="variable">$SSH_PORT</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"SSH_IP_LIST: <span class="variable">$SSH_IP_LIST</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"USERNAME: <span class="variable">$USERNAME</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"RUN_SERVER: <span class="variable">$RUN_SERVER</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"REMOTE_JAR_DIR: <span class="variable">$REMOTE_JAR_DIR</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"JENKINS_JAR_FILE: <span class="variable">$JENKINS_JAR_FILE</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"JAR_COMMOND: <span class="variable">$JAR_COMMOND</span>"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"-------------------- end print env var --------------------"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### IP 数量</span></span><br><span class="line">IP_LIST=1</span><br><span class="line">HOST_COUNT=$(<span class="built_in">echo</span> <span class="variable">$&#123;SSH_IP_LIST&#125;</span> | wc -w)</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 默认定义时间为40秒</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;SLEEP_SEC&#125;</span>"</span> == <span class="string">""</span> ];<span class="keyword">then</span></span><br><span class="line">    SLEEP_SEC=40</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### 检查是否添加公钥</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">SSH_CHECK</span></span>()&#123;</span><br><span class="line">    ssh -p <span class="variable">$&#123;SSH_PORT&#125;</span> -o <span class="string">"StrictHostKeyChecking=no"</span> <span class="variable">$&#123;USERNAME&#125;</span>@<span class="variable">$&#123;SSH_HOST&#125;</span> <span class="string">"uname -n"</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"$?"</span> -ne 0 ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> -e <span class="string">"Jenkins 登录失败, <span class="variable">$&#123;SSH_HOST&#125;</span> 没有添加 SSH 公钥，请把 Jenkins 公钥添加到 <span class="variable">$&#123;SSH_HOST&#125;</span> \n"</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"或检查 <span class="variable">$&#123;SSH_HOST&#125;</span>  ~/.ssh 目录与 ~/.ssh/authorized_keys 文件权限(chmod 700 ~/.ssh &amp;&amp; chmod 600 ~/.ssh/authorized_keys)"</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 构建目录，如果失败可以验证客户端没权限</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">RUN_DIR</span></span>()&#123;  </span><br><span class="line">    ssh -p <span class="variable">$&#123;SSH_PORT&#125;</span> -o <span class="string">"StrictHostKeyChecking=no"</span> <span class="variable">$&#123;USERNAME&#125;</span>@<span class="variable">$&#123;SSH_HOST&#125;</span> <span class="string">"uname -n;/bin/mkdir -p <span class="variable">$&#123;REMOTE_JAR_DIR&#125;</span>"</span></span><br><span class="line">    RUN_ID=`<span class="built_in">echo</span> $?`</span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;RUN_ID&#125;</span>"</span> -ne 0 ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;SSH_HOST&#125;</span> 的 <span class="variable">$&#123;USERNAME&#125;</span> 用户创建目录失败，请检查 <span class="variable">$&#123;USERNAME&#125;</span> 用户是否有权限"</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 存放日志目录</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">LOG_PATH_DIR</span></span>()&#123;  </span><br><span class="line">    ssh -p <span class="variable">$&#123;SSH_PORT&#125;</span> -o <span class="string">"StrictHostKeyChecking=no"</span> <span class="variable">$&#123;USERNAME&#125;</span>@<span class="variable">$&#123;SSH_HOST&#125;</span> <span class="string">"uname -n;/bin/mkdir -p <span class="variable">$&#123;LOG_PATH&#125;</span>"</span></span><br><span class="line">    RUN_ID=`<span class="built_in">echo</span> $?`</span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;RUN_ID&#125;</span>"</span> -ne 0 ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;SSH_HOST&#125;</span> 的 <span class="variable">$&#123;USERNAME&#125;</span> 用户创建目录失败，请检查 <span class="variable">$&#123;USERNAME&#125;</span> 用户是否有权限"</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">RSYNC_JAR</span></span>()&#123;  </span><br><span class="line">    rsync -azP --delete -e <span class="string">"ssh -p <span class="variable">$SSH_PORT</span> -o 'StrictHostKeyChecking=no'"</span> <span class="variable">$&#123;JENKINS_JAR_FILE&#125;</span> <span class="variable">$&#123;USERNAME&#125;</span>@<span class="variable">$&#123;SSH_HOST&#125;</span>:<span class="variable">$&#123;REMOTE_JAR_DIR&#125;</span> &gt; /dev/null</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">JAR_PID</span></span>()&#123;  </span><br><span class="line">    PID=$(ssh -p <span class="variable">$&#123;SSH_PORT&#125;</span> -o <span class="string">"StrictHostKeyChecking=no"</span> <span class="variable">$&#123;USERNAME&#125;</span>@<span class="variable">$&#123;SSH_HOST&#125;</span> <span class="string">"/usr/sbin/lsof -i:<span class="variable">$&#123;JAR_PORT&#125;</span> | grep -vi PID | awk '&#123;print \$2&#125;'"</span>)</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$PID</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">STOP_JAR</span></span>()&#123;  </span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$&#123;PID&#125;</span>"</span> ] || [ -n <span class="string">"<span class="variable">$&#123;PID2&#125;</span>"</span> ];<span class="keyword">then</span>    </span><br><span class="line">        ssh -p <span class="variable">$&#123;SSH_PORT&#125;</span> -o <span class="string">"StrictHostKeyChecking=no"</span> <span class="variable">$&#123;USERNAME&#125;</span>@<span class="variable">$&#123;SSH_HOST&#125;</span> <span class="string">"kill -9 <span class="variable">$PID</span> &gt; /dev/null 2&gt;&amp;1"</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"INFO: <span class="variable">$&#123;JAR_FILE&#125;</span> 进程已杀"</span></span><br><span class="line">    <span class="keyword">else</span>    </span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"INFO: <span class="variable">$&#123;JAR_FILE&#125;</span> is Down"</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    PID=<span class="string">""</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">START_JAR</span></span>()&#123;  </span><br><span class="line">    ssh -p <span class="variable">$&#123;SSH_PORT&#125;</span> -o <span class="string">"StrictHostKeyChecking=no"</span> <span class="variable">$&#123;USERNAME&#125;</span>@<span class="variable">$&#123;SSH_HOST&#125;</span> <span class="string">"source /etc/profile &gt; /dev/null; cd <span class="variable">$&#123;REMOTE_JAR_DIR&#125;</span>; <span class="variable">$&#123;JAR_COMMOND&#125;</span> "</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">CHECK_JAR</span></span>()&#123; </span><br><span class="line">    PID=$(ssh -p <span class="variable">$&#123;SSH_PORT&#125;</span> -o <span class="string">"StrictHostKeyChecking=no"</span> <span class="variable">$&#123;USERNAME&#125;</span>@<span class="variable">$&#123;SSH_HOST&#125;</span> <span class="string">"/usr/sbin/lsof -i:<span class="variable">$&#123;JAR_PORT&#125;</span> | grep -vi PID | awk '&#123;print \$2&#125;'"</span>)</span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$PID</span>"</span> != <span class="string">""</span> ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;SSH_HOST&#125;</span> 的 <span class="variable">$&#123;JAR_FILE&#125;</span> 启动成功"</span> </span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;SSH_HOST&#125;</span> 的 <span class="variable">$&#123;JAR_FILE&#125;</span> 启动失败,请运维登录服务器查看进程或相关启动日志"</span> </span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> SSH_HOST <span class="keyword">in</span> <span class="variable">$SSH_IP_LIST</span></span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">    SSH_CHECK </span><br><span class="line">    RUN_DIR    </span><br><span class="line">    LOG_PATH_DIR</span><br><span class="line">    RSYNC_JAR </span><br><span class="line">    JAR_PID </span><br><span class="line">    <span class="comment">#STOP_JAR</span></span><br><span class="line">    START_JAR</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;IP_LIST&#125;</span>"</span> -le <span class="string">"<span class="variable">$&#123;HOST_COUNT&#125;</span>"</span> ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"正在检测 <span class="variable">$&#123;SSH_HOST&#125;</span> 的 <span class="variable">$&#123;JAR_FILE&#125;</span> 程序是否成功启动，请等待 <span class="variable">$&#123;SLEEP_SEC&#125;</span> 秒!"</span></span><br><span class="line">        sleep <span class="variable">$&#123;SLEEP_SEC&#125;</span></span><br><span class="line">        <span class="comment">#CHECK_JAR</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;IP_LIST&#125;</span>"</span> -gt <span class="string">"<span class="variable">$&#123;HOST_COUNT&#125;</span>"</span> ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"INFO: &lt;<span class="variable">$&#123;IP_LIST&#125;</span>&gt; 更新下一台机..."</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">let</span> IP_LIST=IP_LIST+1</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<p>回到jenkins去点击<code>[Build Now]</code>，在<code>[Console Output]</code>观看它的构建情况。等构建成功后，我们登录<code>192.168.30.241</code>查看情况：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/</span><br><span class="line">$ ssh -p 12022 root@192.168.30.241</span><br><span class="line"></span><br><span class="line">Last login: Thu Oct 11 11:18:50 2018 from 10.1.23.231</span><br><span class="line">[root@192.168.30.241 ~]<span class="comment"># ls /www/</span></span><br><span class="line">logs  web</span><br><span class="line">[root@192.168.30.241 ~]<span class="comment"># ls /www/web/my-app/dev/</span></span><br><span class="line">my-app-1.0-SNAPSHOT.jar</span><br><span class="line">[root@192.168.30.241 ~]<span class="comment"># more /www/logs/my-app/my-app.log </span></span><br><span class="line">Hello World!</span><br></pre></td></tr></table></figure></p>
<p>从上述输出可知，我们的构建已经成功！！！</p>
<p><strong>将脚本存放在<code>jar.sh</code>中的好处是此脚本可以供多个项目共同使用，只要在<code>Execute shell</code>中根据不同项目定义不同的变量值即可。</strong></p>
<h4 id="示例D、构建指定的git分支"><a href="#示例D、构建指定的git分支" class="headerlink" title="示例D、构建指定的git分支"></a>示例D、构建指定的git分支</h4><p>要实现这个功能，我们要在jenkins安装一个插件<code>Git Parameter</code>：<br><img src="/img/jenkins-30.png" alt=""></p>
<p>我们还是以示例A的为例，去到它的配置中，选中<code>This project is parameterized</code>，点<code>Add parameter</code>-&gt;<code>Git Parameter</code>，设置如下：<br><img src="/img/jenkins-31.png" alt=""></p>
<p>并在<code>Branches to build</code>按下图所示填：<br><img src="/img/jenkins-32.png" alt=""></p>
<p>回到mvn-test这个job，你会发现原先的<code>Build Now</code>已经变成了<code>Build with Parameters</code>，我们点它：<br><img src="/img/jenkins-33.png" alt=""></p>
<p>至此，就可以构建我们想构建的分支了。</p>
<h4 id="示例E、当构建出错的时候，如何回滚-rollback-到上一个版本"><a href="#示例E、当构建出错的时候，如何回滚-rollback-到上一个版本" class="headerlink" title="示例E、当构建出错的时候，如何回滚(rollback)到上一个版本"></a>示例E、当构建出错的时候，如何回滚(rollback)到上一个版本</h4><p>要实现这个功能，我们要在jenkins安装一个插件<code>Copy Artifact</code>：<br><img src="/img/jenkins-34.png" alt=""></p>
<p>未完待续……</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/10/05/jenkins-install/" data-id="cjogzpskx000yvv2iuvfzdbx9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/jenkins/">jenkins</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ELK-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/02/ELK-install/" class="article-date">
  <time datetime="2018-10-02T03:09:56.000Z" itemprop="datePublished">2018-10-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/02/ELK-install/">ELK 日志系统的搭建</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本篇将介绍 ELK 日志系统的搭建，我们将在一台机器上面搭建，系统配置如下：<br><img src="/img/system-property.png" alt="" title="系统配置"></p>
<p><code>logstash</code>的整体结构图如下：<br><img src="/img/elk-structure.png" alt="" title="来源：https://www.elastic.co/guide/en/logstash/current/static/images/basic_logstash_pipeline.png"></p>
<p>我们将使用<code>redis</code>作为上图中的<code>INPUTS</code>，而<code>elasticsearch</code>作为上图中的<code>OUTPUTS</code>，这也是<code>logstash</code>官方的推荐。而它们的安装可以参考以下例子：<br><code>redis</code>的安装请参考：<a href="../../../../2018/08/07/redis-install/">redis 的安装使用</a><br><code>elasticsearch</code>的安装请参考：<a href="../../../../2018/09/16/elasticsearch-install/">elasticsearch 单节点安装</a></p>
<p><strong> 注意：elasticsearch、logstash、kibana它们的版本最好保持一致，这里都是使用6.4.0版本。 </strong></p>
<h3 id="kibana的安装将在本篇的稍后介绍，下面先介绍下logstash的安装"><a href="#kibana的安装将在本篇的稍后介绍，下面先介绍下logstash的安装" class="headerlink" title="kibana的安装将在本篇的稍后介绍，下面先介绍下logstash的安装"></a><code>kibana</code>的安装将在本篇的稍后介绍，下面先介绍下<code>logstash</code>的安装</h3><p>首先，我们要将<code>logstash</code>安装包下载回来，可以在它的<a href="https://artifacts.elastic.co/downloads/logstash/logstash-6.4.0.tar.gz" target="_blank" rel="noopener">官网</a>下载，当然，我们也可以从这里下载 <a href="https://pan.baidu.com/s/10p4YqzwSk1ixLqvSuv2sAA" title="百度网盘" target="_blank" rel="noopener">logstash-6.4.0.tar.gz</a>，推荐从<code>logstash</code>官网下载对应版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.0.tar.gz</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.0.tar.gz.sha512</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性，在下载的时候要将 SHA512 文件也下载回来</span><br><span class="line">$ sha512sum -c logstash-6.4.0.tar.gz.sha512 </span><br><span class="line">logstash-6.4.0.tar.gz: OK</span><br><span class="line"></span><br><span class="line">$ tar xzf logstash-6.4.0.tar.gz</span><br></pre></td></tr></table></figure>
<p>解压后，得到目录<code>logstash-6.4.0</code>，可以查看下它包含有哪些文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0</span><br><span class="line">$ ls</span><br><span class="line"></span><br><span class="line">bin           data          lib          logstash-core             NOTICE.TXT  x-pack</span><br><span class="line">config        Gemfile       LICENSE.txt  logstash-core-plugin-api  tools</span><br><span class="line">CONTRIBUTORS  Gemfile.lock  logs         modules                   vendor</span><br></pre></td></tr></table></figure></p>
<h4 id="测试安装是否成功：以标准输入、标准输出作为input-output"><a href="#测试安装是否成功：以标准输入、标准输出作为input-output" class="headerlink" title="测试安装是否成功：以标准输入、标准输出作为input, output"></a>测试安装是否成功：以标准输入、标准输出作为input, output</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0/bin</span><br><span class="line">$ ./logstash -e <span class="string">'input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123; &#125; &#125;'</span></span><br><span class="line"></span><br><span class="line">Sending Logstash logs to /home/hewentian/ProjectD/logstash-6.4.0/logs <span class="built_in">which</span> is now configured via log4j2.properties</span><br><span class="line">[2018-10-02T14:25:37,017][WARN ][logstash.config.source.multilocal] Ignoring the <span class="string">'pipelines.yml'</span> file because modules or <span class="built_in">command</span> line options are specified</span><br><span class="line">[2018-10-02T14:25:38,201][INFO ][logstash.runner          ] Starting Logstash &#123;<span class="string">"logstash.version"</span>=&gt;<span class="string">"6.4.0"</span>&#125;</span><br><span class="line">[2018-10-02T14:25:41,748][INFO ][logstash.pipeline        ] Starting pipeline &#123;:pipeline_id=&gt;<span class="string">"main"</span>, <span class="string">"pipeline.workers"</span>=&gt;4, <span class="string">"pipeline.batch.size"</span>=&gt;125, <span class="string">"pipeline.batch.delay"</span>=&gt;50&#125;</span><br><span class="line">[2018-10-02T14:25:41,919][INFO ][logstash.pipeline        ] Pipeline started successfully &#123;:pipeline_id=&gt;<span class="string">"main"</span>, :thread=&gt;<span class="string">"#&lt;Thread:0x4c1685e4 run&gt;"</span>&#125;</span><br><span class="line">The stdin plugin is now waiting <span class="keyword">for</span> input:</span><br><span class="line">[2018-10-02T14:25:41,990][INFO ][logstash.agent           ] Pipelines running &#123;:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]&#125;</span><br><span class="line">[2018-10-02T14:25:42,396][INFO ][logstash.agent           ] Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#此时窗口在等待输入</span></span><br><span class="line"></span><br><span class="line">hello world</span><br><span class="line"></span><br><span class="line"><span class="comment">#下面是logstash的输出结果</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">      <span class="string">"@version"</span> =&gt; <span class="string">"1"</span>,</span><br><span class="line">    <span class="string">"@timestamp"</span> =&gt; 2018-10-02T06:25:59.608Z,</span><br><span class="line">       <span class="string">"message"</span> =&gt; <span class="string">"hello world"</span>,</span><br><span class="line">          <span class="string">"host"</span> =&gt; <span class="string">"hewentian-Lenovo-IdeaPad-Y470"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的测试结果可知，软件安装正确，下面开始我们的定制配置。</p>
<p>配置文件放在config目录下，此目录下已经有一个示例配置，因为我们要将redis作为我们的INPUTS，所以我们要建立它的配置文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0/config</span><br><span class="line">$ cp logstash-sample.conf logstash-redis.conf</span><br><span class="line">$ </span><br><span class="line">$ vi logstash-redis.conf</span><br></pre></td></tr></table></figure></p>
<p>在<code>logstash-redis.conf</code>中配置如下，这里暂未配置FILTERS（后面会讲到如何配置）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sample Logstash configuration for creating a simple</span></span><br><span class="line"><span class="comment"># Redis -&gt; Logstash -&gt; Elasticsearch pipeline.</span></span><br><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line">  redis &#123;</span><br><span class="line">    <span class="built_in">type</span> =&gt; <span class="string">"systemlog"</span></span><br><span class="line">    host =&gt; <span class="string">"127.0.0.1"</span></span><br><span class="line">    port =&gt; 6379</span><br><span class="line">    password =&gt; <span class="string">"abc123"</span></span><br><span class="line">    db =&gt; 0</span><br><span class="line">    data_type =&gt; <span class="string">"list"</span></span><br><span class="line">    key =&gt; <span class="string">"systemlog"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  <span class="keyword">if</span> [<span class="built_in">type</span>] == <span class="string">"systemlog"</span> &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">      hosts =&gt; [<span class="string">"http://127.0.0.1:9200"</span>]</span><br><span class="line">      index =&gt; <span class="string">"redis-systemlog-%&#123;+YYYY.MM.dd&#125;"</span></span><br><span class="line">      <span class="comment">#user =&gt; "elastic"</span></span><br><span class="line">      <span class="comment">#password =&gt; "changeme"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在启动<code>logstash</code>前，验证一下配置文件是否正确，这是一个好习惯：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0/bin</span><br><span class="line">$ ./logstash -f ../config/logstash-redis.conf -t</span><br></pre></td></tr></table></figure></p>
<p>如果你见到如下输出，则配置正确：</p>
<pre><code>Sending Logstash logs to /home/hewentian/ProjectD/logstash-6.4.0/logs which is now configured via log4j2.properties
[2018-09-30T16:32:45,043][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=&gt;&quot;path.queue&quot;, :path=&gt;&quot;/home/hewentian/ProjectD/logstash-6.4.0/data/queue&quot;}
[2018-09-30T16:32:45,064][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=&gt;&quot;path.dead_letter_queue&quot;, :path=&gt;&quot;/home/hewentian/ProjectD/logstash-6.4.0/data/dead_letter_queue&quot;}
[2018-09-30T16:32:46,030][WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified
Configuration OK
[2018-09-30T16:32:50,630][INFO ][logstash.runner          ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash
</code></pre><p>接下来，就可以启动logstash了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/logstash-6.4.0/bin</span><br><span class="line">$ ./logstash -f ../config/logstash-redis.conf</span><br></pre></td></tr></table></figure></p>
<p>如果见到如下输出，则启动成功：</p>
<pre><code>[2018-09-30T16:34:44,175][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=&gt;9600}
</code></pre><h4 id="下面进行简单的测试"><a href="#下面进行简单的测试" class="headerlink" title="下面进行简单的测试"></a>下面进行简单的测试</h4><p>我们首先，往redis中推入3条记录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_master/src</span><br><span class="line">$ ./redis-cli -h 127.0.0.1</span><br><span class="line">127.0.0.1:6379&gt; AUTH abc123</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lpush systemlog hello world</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; lpush systemlog <span class="string">'&#123;"name":"Tim Ho","age":23,"student":true&#125;'</span></span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br></pre></td></tr></table></figure></p>
<p>启动elastchsearch-head可以看到数据已经进入到es中了：<br><img src="/img/elk-head-1.png" alt="" title="elk-head-1"></p>
<p>你会发现上面推到<code>systemlog</code>中的信息如果是JSON格式，则在elasticsearch中会自动解析到相应的field中，否则会放到默认的field：<code>message</code>中。</p>
<h3 id="kibana的安装"><a href="#kibana的安装" class="headerlink" title="kibana的安装"></a>kibana的安装</h3><p><code>kibana</code>的安装很简单，将<code>kibana</code>安装包下载回来，可以在它的<a href="https://artifacts.elastic.co/downloads/kibana/kibana-6.4.0-linux-x86_64.tar.gz" target="_blank" rel="noopener">官网</a>下载，当然，我们也可以从这里下载 <a href="https://pan.baidu.com/s/1-h0z7DR2uhuwhCn0_vNc4w" title="百度网盘" target="_blank" rel="noopener">kibana-6.4.0-linux-x86_64.tar.gz</a>，推荐从<code>kibana</code>官网下载对应版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/kibana/kibana-6.4.0-linux-x86_64.tar.gz</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/kibana/kibana-6.4.0-linux-x86_64.tar.gz.sha512</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性，在下载的时候要将 SHA512 文件也下载回来</span><br><span class="line">$ sha512sum -c kibana-6.4.0-linux-x86_64.tar.gz.sha512 </span><br><span class="line">kibana-6.4.0-linux-x86_64.tar.gz: OK</span><br><span class="line"></span><br><span class="line">$ tar xzf kibana-6.4.0-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure>
<p>对<code>kibana</code>配置要查看的<code>elasticsearch</code>，只需修改如下配置项即可，如果是在本机安装<code>elasticsearch</code>，并且使用默认的9200端口，则无需配置。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kibana-6.4.0-linux-x86_64/config</span><br><span class="line">$ vi kibana.yml</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改如下配置项，如果使用默认的，则无需修改</span></span><br><span class="line"><span class="comment">#server.port: 5601</span></span><br><span class="line"><span class="comment">#elasticsearch.url: "http://localhost:9200"</span></span><br><span class="line"><span class="comment">#elasticsearch.username: "user"</span></span><br><span class="line"><span class="comment">#elasticsearch.password: "pass"</span></span><br></pre></td></tr></table></figure></p>
<p>接着启动<code>kibana</code>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/kibana-6.4.0-linux-x86_64/bin</span><br><span class="line">$ ./kibana <span class="comment"># 或者以后台方式运行 nohup ./kibana &amp;</span></span><br></pre></td></tr></table></figure></p>
<p>打开浏览器，并输入下面的地址：<br><a href="http://localhost:5601" target="_blank" rel="noopener">http://localhost:5601</a></p>
<p>你将看到如下界面：<br><img src="/img/elk-kibana-1.png" alt="" title="kibana初始界面"></p>
<p>点击上图中的<code>[Management]-&gt;[Index Patterns]-&gt;[Create index pattern]</code>，输入<code>index name：redis-systemlog-*</code>，如下图<br><img src="/img/elk-kibana-2.png" alt="" title="kibana配置index name界面"></p>
<p>点击<code>[Next step]</code>按钮，并在接下来的界面中的<code>Time Filter field name</code>中选择<code>I don&#39;t want to user the Time Filter</code>，最后点击<code>Create index pattern</code>完成创建。接着点击左则的<code>[Discover]</code>并在左则的界面中选择中<code>redis-systemlog-*</code>，你将看到如下结果：<br><img src="/img/elk-kibana-3.png" alt="" title="kibana查询界面"></p>
<p>至此，简单的 ELK 基本搭建完毕。下面展示一个简单的配置示例：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sample Logstash configuration for creating a simple</span></span><br><span class="line"><span class="comment"># Redis -&gt; Logstash -&gt; Elasticsearch pipeline.</span></span><br><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line">  <span class="comment"># system log</span></span><br><span class="line">  redis &#123;</span><br><span class="line">    <span class="built_in">type</span> =&gt; <span class="string">"systemlog"</span></span><br><span class="line">    host =&gt; <span class="string">"127.0.0.1"</span></span><br><span class="line">    port =&gt; 6379</span><br><span class="line">    password =&gt; <span class="string">"abc123"</span></span><br><span class="line">    db =&gt; 0</span><br><span class="line">    data_type =&gt; <span class="string">"list"</span></span><br><span class="line">    key =&gt; <span class="string">"systemlog"</span></span><br><span class="line">    codec  =&gt; <span class="string">"json"</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># user log</span></span><br><span class="line">  redis &#123;</span><br><span class="line">    <span class="built_in">type</span> =&gt; <span class="string">"userlog"</span></span><br><span class="line">    host =&gt; <span class="string">"127.0.0.1"</span></span><br><span class="line">    port =&gt; 6379</span><br><span class="line">    password =&gt; <span class="string">"abc123"</span></span><br><span class="line">    db =&gt; 0</span><br><span class="line">    data_type =&gt; <span class="string">"list"</span></span><br><span class="line">    key =&gt; <span class="string">"userlog"</span></span><br><span class="line">    codec  =&gt; <span class="string">"json"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; [<span class="string">"http://127.0.0.1:9200"</span>]</span><br><span class="line">    index =&gt; <span class="string">"%&#123;type&#125;-%&#123;+YYYY.MM&#125;"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="下面我们将继续探索它的高级功能。"><a href="#下面我们将继续探索它的高级功能。" class="headerlink" title="下面我们将继续探索它的高级功能。"></a>下面我们将继续探索它的高级功能。</h3><p>很多时候，对于<code>systemlog</code>中的某条信息（不一定是JSON格式），如果我们只需要某些信息，那我们又怎样做呢？这里就需要使用FILTERS了。</p>
<p>在FILTERS中使用grok正则表达式，关于grok，可以参见这里的说明：<br><a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html</a></p>
<p>未完，待续……</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/10/02/ELK-install/" data-id="cjogzpsij0000vv2itqh3d05c" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-elasticsearch-note" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/18/elasticsearch-note/" class="article-date">
  <time datetime="2018-09-18T02:21:01.000Z" itemprop="datePublished">2018-09-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/18/elasticsearch-note/">elasticsearch 学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>参考资料：<br><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/index.html" title="Elasticsearch 权威指南" target="_blank" rel="noopener">Elasticsearch 权威指南</a><br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html" title="Elasticsearch Reference" target="_blank" rel="noopener">Elasticsearch Reference</a><br><a href="http://es.xiaoleilu.com/080_Structured_Search/20_contains.html" target="_blank" rel="noopener">http://es.xiaoleilu.com/080_Structured_Search/20_contains.html</a><br><a href="https://github.com/searchbox-io/Jest/tree/master/jest/src/test/java/io/searchbox/core">https://github.com/searchbox-io/Jest/tree/master/jest/src/test/java/io/searchbox/core</a></p>
<p>首先，你必须至少有一台<code>elasticsearch</code>服务器可以使用，如果还没安装，可以参考我的上两篇 <a href="../../../../2018/09/16/elasticsearch-install" title="elasticsearch 单节点安装">elasticsearch 单节点安装</a>、<a href="../../../../2018/09/17/elasticsearch-cluster" title="elasticsearch 集群的搭建">elasticsearch 集群的搭建</a></p>
<p>使用JAVA API来操作<code>elasticsearch</code>的例子可以在这里找到：<a href="https://github.com/hewentian/studyResource/blob/master/src/main/java/com/hewentian/util/EsJestUtil.java">EsJestUtil.java</a>、<a href="https://github.com/hewentian/studyResource/blob/master/src/main/java/com/hewentian/es/EsJestDemo.java">EsJestDemo.java</a></p>
<h4 id="要单独创建一个索引"><a href="#要单独创建一个索引" class="headerlink" title="要单独创建一个索引"></a>要单独创建一个索引</h4><pre>
curl -XPUT 'http://localhost:9200/user_index' -H 'Content-Type: application/json' -d '{
    "settings" : {
        "index" : {
            "number_of_shards" : 4,
            "number_of_replicas" : 1
        }
    }
}'

{"acknowledged":true,"shards_acknowledged":true,"index":"user_index"}
</pre>


<h4 id="删除索引的命令"><a href="#删除索引的命令" class="headerlink" title="删除索引的命令"></a>删除索引的命令</h4><pre>
curl -XDELETE 'http://localhost:9200/user_index/'

{"acknowledged":true}
</pre>


<h4 id="为user-index中的user创建mapping"><a href="#为user-index中的user创建mapping" class="headerlink" title="为user_index中的user创建mapping"></a>为user_index中的user创建mapping</h4><pre>
curl -XPUT 'http://localhost:9200/user_index/_mapping/user' -H 'Content-Type: application/json' -d '{
    "properties": {
        "id": {
            "type": "long",
            "index": "false"
        },
        "name": {
            "type": "keyword"
        },
        "age": {
            "type": "integer"
        },
        "tags": {
            "type": "keyword",
            "boost": 3.0
       },
       "birthday": {
            "type": "date",
            "format": "strict_date_optional_time || epoch_millis || yyyy-MM-dd HH:mm:ss"
       }
   }
}'
</pre>


<h4 id="ES中的一些概念"><a href="#ES中的一些概念" class="headerlink" title="ES中的一些概念"></a>ES中的一些概念</h4><p><strong>cluster</strong><br>代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。</p>
<p><strong>shards</strong><br>代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。</p>
<p><strong>replicas</strong><br>代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。</p>
<p><strong>recovery</strong><br>代表数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。</p>
<p><strong>river</strong><br>代表es的一个数据源，也是其它存储方式（如：数据库）同步数据到es的一个方法。它是以插件方式存在的一个es服务，通过读取river中的数据并把它索引到es中，官方的river有couchDB的，RabbitMQ的，Twitter的，Wikipedia的。</p>
<p><strong>gateway</strong><br>代表es索引快照的存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到本地硬盘。gateway对索引快照进行存储，当这个es集群关闭再重新启动时就会从gateway中读取索引备份数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。</p>
<p><strong>discovery.zen</strong><br>代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。</p>
<p><strong>Transport</strong><br>代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。</p>
<p>Date formats can be customised, but if no format is specified then it uses the default:</p>
<pre><code>&quot;strict_date_optional_time||epoch_millis&quot;
</code></pre><p>if you set it like this:</p>
<pre><code>PUT my_index
{
  &quot;mappings&quot;: {
    &quot;_doc&quot;: {
      &quot;properties&quot;: {
        &quot;date&quot;: {
          &quot;type&quot;:   &quot;date&quot;,
          &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;
        }
      }
    }
  }
}
</code></pre><p>you can use the below method to set date:</p>
<pre>
PUT my_index/_doc/1
{ "date": "2015-01-01 12:10:30" } 

PUT my_index/_doc/2
{ "date": "2015-01-01T12:10:30Z" } 

PUT my_index/_doc/3
{ "date": 1420070400001 }
</pre>

<h4 id="文件的部分更新"><a href="#文件的部分更新" class="headerlink" title="文件的部分更新"></a>文件的部分更新</h4><p>文档是不可变的：他们不能被修改，只能被替换。 update API 必须遵循同样的规则。 从外部来看，我们在一个文档的某个位置进行部分更新。然而在内部， update API 简单使用与之前描述相同的 检索-修改-重建索引 的处理过程。 区别在于这个过程发生在分片内部，这样就避免了多次请求的网络开销。通过减少检索和重建索引步骤之间的时间，我们也减少了其他进程的变更带来冲突的可能性。</p>
<p>方法一：update 请求最简单的一种形式是接收文档的一部分作为 doc 的参数， 它只是与现有的文档进行合并。对象被合并到一起，覆盖现有的字段，增加新的字段。 例如，我们增加字段 tags 和 views 到我们的博客文章，如下所示：</p>
<pre><code>POST /website/blog/1/_update
{
       &quot;doc&quot; : {
          &quot;tags&quot; : [ &quot;testing&quot; ],
          &quot;views&quot;: 0
       }
}
</code></pre><p>测试示例：</p>
<pre>
先插件一条数据：
curl -XPUT 'http://localhost:9200/facebook/tuser/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "tim",
    "post_date": "2009-11-15T13:12:00",
    "message": "Elasticsearch, so far so good?"
}'

再将这条数所的 message 字段修改一下
curl -XPOST 'http://localhost:9200/facebook/tuser/1/_update' -H 'Content-Type: application/json' -d '
{
    "doc":{
        "message": "Elasticsearch, so far so good? yes"
    }
}'
</pre>


<p>方法二：使用脚本部分更新文档编辑<br>脚本可以在 update API中用来改变 _source 的字段内容， 它在更新脚本中称为 ctx._source 。 例如，我们可以使用脚本来增加博客文章中 views 的数量：</p>
<pre><code>POST /website/blog/1/_update
{
       &quot;script&quot; : &quot;ctx._source.views+=1&quot;
}
</code></pre><pre>
curl -XPOST 'http://127.0.0.1:9200/facebook/tuser/1/_update' -H 'Content-Type: application/json' -d '
{
    "script" : "ctx._source.message=\"yes, you are right.\""
}'
</pre>

<p>下面的命令可以列出每个 Index 所包含的 Type<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XGET <span class="string">'http://127.0.0.1:9200/user_index/_mapping?pretty=true'</span></span><br></pre></td></tr></table></figure></p>
<ol>
<li>cluster.name<br>配置es的集群名称，默认是elasticsearch，不同的集群用名字来区分，es会自动发现在同一网段下的es，配置成相同集群名字的各个节点形成一个集群。如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。</li>
<li>http.port<br>设置对外服务的http端口，默认为9200。不能相同，否则会冲突。</li>
</ol>
<p>ES有很多插件，我们可以选择安装一些，例如，以安装head插件为例。有两种方式安装，一种为在线安装，另一种为本地安装，本地安装要下载插件(git clone)。<br>插件下载地址为：<br><a href="https://github.com/mobz/elasticsearch-head">https://github.com/mobz/elasticsearch-head</a></p>
<p>这里以在线安装为例，我之前在介绍<a href="../../../../2018/09/16/elasticsearch-install" title="elasticsearch 单节点安装">elasticsearch 单节点安装</a>中使用的是本地安装，推荐使用本地安装。旧版本安装过程如下：<br>进入ES的HOME目录，执行plugin命令，如下，</p>
<pre><code>cd ${ES_HOME}/bin
./elasticsearch-plugin install mobz/elasticsearch-head
</code></pre><p>安装完毕后，要重启ES。在浏览器中输入：<a href="http://localhost:9200/_plugin/head/，如果看到了页面，则表明安装成功。" target="_blank" rel="noopener">http://localhost:9200/_plugin/head/，如果看到了页面，则表明安装成功。</a></p>
<p>ES一次查询，最多返回10条，但hits会显示total一共有多少条，要使用from, size指定。<br>在ES里面删除数据的时候要非常小心，如果全部都清空了，可能整个库的MAPPING都会有问题。这时，一些原先可以执行的语句可能会无法执行</p>
<h4 id="以下是一些常查询："><a href="#以下是一些常查询：" class="headerlink" title="以下是一些常查询："></a>以下是一些常查询：</h4><pre>
{
  "query": {
    "bool": {
      "should": [
        {
          "match": {
            "_id": "http://www.abc.com"
          }
        },
        {
          "match": {
            "_id": "http://www.csdn.net/tag/scala"
          }
        }
      ]
    }
  }
}


{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "address": "*canton*"
          }
        },
        {
          "match": {
            "name": "Tim"
          }
        }
      ]
    }
  }
}


{
  "query": {
    "bool": {
      "must": [
        {
          "bool": {
            "should": [
              {
                "match": {
                  "title": {
                    "minimum_should_match": "100%",
                    "query": "Air Quality"
                  }
                }
              },
              {
                "match": {
                  "body_text": {
                    "minimum_should_match": "100%",
                    "query": "Air Quality"
                  }
                }
              }
            ]
          }
        },
        {
          "wildcard": {
            "user_ids": "*760aa069-2ed2-40d6-89da-f62e83f82887*"
          }
        }
      ]
    }
  },
  "from": 0,
  "size": 20
}


{
  "sort": [
    {
      "updatetime_6h": {
        "order": "desc"
      }
    },
    {
      "_score": {
        "order": "desc"
      }
    }
  ],
  "query": {
    "filtered": {
      "query": {
        "bool": {
          "must_not": [],
          "should": [
            {
              "bool": {
                "should": [
                  {
                    "match_phrase": {
                      "app_type.title": {
                        "query": "china"
                      }
                    }
                  },
                  {
                    "match_phrase": {
                      "app_type.title": {
                        "query": "中国"
                      }
                    }
                  }
                ]
              }
            },
            {
              "bool": {
                "should": [
                  {
                    "match_phrase": {
                      "app_type.body_text": {
                        "query": "china"
                      }
                    }
                  },
                  {
                    "match_phrase": {
                      "app_type.body_text": {
                        "query": "中国"
                      }
                    }
                  }
                ]
              }
            }
          ],
          "must": []
        }
      },
      "filter": {
        "bool": {
          "should": [],
          "must": [
            {
              "range": {
                "updatetime": {
                  "lte": 1474617163524
                }
              }
            },
            {
              "query": {
                "wildcard": {
                  "user_ids": "*760aa069-2ed2-40d6-89da-f62e83f82887*"
                }
              }
            }
          ]
        }
      }
    }
  },
  "from": 0,
  "size": 20
}

GET /people/user/_search
{
  "query": {
    "bool":{
      "must":[{
        "match":{"birthYear":1989}}
        ]
    }
  },
  "aggregations" : {
    "CATEGORY" : {
      "terms" : {
        "field" : "deposit",
        "size" : 100,
        "order" : {
          "_count" : "desc"
        }
      }
    }
  },
  "size":0
}
</pre>

<h3 id="查询返回某些指定的字段"><a href="#查询返回某些指定的字段" class="headerlink" title="查询返回某些指定的字段"></a>查询返回某些指定的字段</h3><p>如果查询的结果字段很多，而我们仅需要其中的某些字段的时候，我们可能通过<code>_source</code>来指定，比如我们只要userName, address：</p>
<pre>
GET people/user/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "userName": "张三"
          }
        }
      ]
    }
  },
  "_source": [
    "userName",
    "address"
  ],
  "size": 2
}
</pre>

<p>未完待续……</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/09/18/elasticsearch-note/" data-id="cjogzpsjq0009vv2i3r56wuqy" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-elasticsearch-cluster" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/17/elasticsearch-cluster/" class="article-date">
  <time datetime="2018-09-17T02:36:12.000Z" itemprop="datePublished">2018-09-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/17/elasticsearch-cluster/">elasticsearch 集群的搭建</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>下面说说elasticsearch集群的搭建，同样是使用前面例子<a href="../../../../2018/09/16/elasticsearch-install" title="elasticsearch 安装">elasticsearch 单节点安装</a>使用的<code>elasticsearch-6.4.0.tar.gz</code>版本，我在一台机器上安装，所以这是伪集群，当修改为真集群的时候，只要将IP地址修改下即可，下面会说明。</p>
<h3 id="下面开始搭建elasticsearch集群"><a href="#下面开始搭建elasticsearch集群" class="headerlink" title="下面开始搭建elasticsearch集群"></a>下面开始搭建elasticsearch集群</h3><p>创建一个目录用于存放集群使用到的所有实例信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD</span><br><span class="line">$ mkdir elasticsearchCluster	<span class="comment"># 集群的文件都放在这里</span></span><br></pre></td></tr></table></figure></p>
<p>将一个elasticsearch压缩包放到这个目录，我之前已在ProjectD目录下载好了<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster</span><br><span class="line">$ cp /home/hewentian/ProjectD/elasticsearch-6.4.0.tar.gz ./</span><br><span class="line">$ tar xzvf elasticsearch-6.4.0.tar.gz</span><br><span class="line"></span><br><span class="line">为方便起见，这里将其重命名为elasticsearch-node1，先将elasticsearch-node1配置好，</span><br><span class="line">后面会将其复制为elasticsearch-node2, elasticsearch-node3</span><br><span class="line">$ mv elasticsearch-6.4.0 elasticsearch-node1</span><br></pre></td></tr></table></figure></p>
<p>对<code>elasticsearch-node1</code>进行设置：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node1/config</span><br><span class="line">$ vi elasticsearch.yml 		<span class="comment"># 增加下面的配置</span></span><br><span class="line"></span><br><span class="line">cluster.name: hewentian-cluster	<span class="comment"># 配置集群的名字</span></span><br><span class="line">node.name: node-1		<span class="comment"># 配置集群下的节点的名字</span></span><br><span class="line"></span><br><span class="line">node.master: <span class="literal">true</span>		<span class="comment"># 是否有资格被选举为master节点， 默认为 true</span></span><br><span class="line">node.data: <span class="literal">true</span>			<span class="comment"># 设置该节点是否存储数据， 默认为 true</span></span><br><span class="line"></span><br><span class="line">network.host: 127.0.0.1		<span class="comment"># 设置本机IP地址</span></span><br><span class="line">http.port: 9201			<span class="comment"># 将端口设置成9201</span></span><br><span class="line">transport.tcp.port: 9301	<span class="comment"># 内部节点之间沟通的端口</span></span><br><span class="line"></span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"127.0.0.1:9301"</span>, <span class="string">"127.0.0.1:9302"</span>, <span class="string">"127.0.0.1:9303"</span>]</span><br><span class="line"></span><br><span class="line">discovery.zen.minimum_master_nodes: 2	<span class="comment"># total number of master-eligible nodes / 2 + 1</span></span><br><span class="line"></span><br><span class="line">action.destructive_requires_name: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">允许跨域，否则 elasticsearch head 不能访问 elasticsearch</span><br><span class="line">http.cors.enabled: <span class="literal">true</span></span><br><span class="line">http.cors.allow-origin: <span class="string">"*"</span></span><br></pre></td></tr></table></figure></p>
<p>这样一个节点就配置好了，我们只要以这个为蓝本，复制出两份，并修改其中的三点：node.name、http.port、transport.tcp.port即可。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster</span><br><span class="line">$ cp -r elasticsearch-node1 elasticsearch-node2</span><br><span class="line">$ cp -r elasticsearch-node1 elasticsearch-node3</span><br><span class="line"></span><br><span class="line">$ ls </span><br><span class="line">elasticsearch-6.4.0.tar.gz  elasticsearch-node1  elasticsearch-node2  elasticsearch-node3</span><br><span class="line"></span><br><span class="line">对 elasticsearch-node2 进行设置，只修改如下三项</span><br><span class="line">$ vi /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node2/config/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">node.name: node-2</span><br><span class="line">http.port: 9202</span><br><span class="line">transport.tcp.port: 9302</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">对 elasticsearch-node3 进行设置，只修改如下三项</span><br><span class="line">$ vi /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node3/config/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">node.name: node-3</span><br><span class="line">http.port: 9203</span><br><span class="line">transport.tcp.port: 9303</span><br></pre></td></tr></table></figure></p>
<p>内存大小的设置，根据机器内存大小而设置，一般不超过系统总内存的一半，分别对三个节点进行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node1/config/</span><br><span class="line">$ vi jvm.options</span><br><span class="line"></span><br><span class="line">-Xms1g</span><br><span class="line">-Xmx1g</span><br></pre></td></tr></table></figure></p>
<p>在每个节点所在的机器上都作下面的配置（下面是根据我机器的情况作的配置，我的是伪集群，所以只配置一次）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ su root			<span class="comment"># 必须在 root 下才有权限修改系统配置文件</span></span><br><span class="line">Password: </span><br><span class="line">$ vi /etc/security/limits.conf	<span class="comment"># 添加如下配置</span></span><br><span class="line">* soft nofile 65536		<span class="comment"># 上面第一个错误有提示</span></span><br><span class="line">* hard nofile 131072		<span class="comment"># 一般为 soft nofile 的2倍</span></span><br><span class="line">* soft nproc 4096		<span class="comment"># 这个设置线程数</span></span><br><span class="line">* hard nproc 8192</span><br><span class="line"></span><br><span class="line">$ vi /etc/sysctl.conf		<span class="comment"># 添加如下配置</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"></span><br><span class="line">$ sysctl -p			<span class="comment"># 最后执行这个命令，你会见到如下输出</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">exit</span>				<span class="comment"># 退出 root</span></span><br></pre></td></tr></table></figure></p>
<p>分别启动三个节点：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node1/bin</span><br><span class="line">$ ./elasticsearch</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node2/bin</span><br><span class="line">$ ./elasticsearch</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearchCluster/elasticsearch-node3/bin</span><br><span class="line">$ ./elasticsearch</span><br></pre></td></tr></table></figure></p>
<p>部分输出如下：</p>
<pre><code>[2018-09-17T17:27:08,325][INFO ][o.e.n.Node               ] [node-1] initializing ...
[2018-09-17T17:27:08,430][INFO ][o.e.e.NodeEnvironment    ] [node-1] using [1] data paths, mounts [[/ (/dev/sda2)]], net usable_space [59.7gb], net total_space [101.7gb], types [ext4]

[2018-09-17T17:27:19,552][DEBUG][o.e.a.ActionModule       ] Using REST wrapper from plugin org.elasticsearch.xpack.security.Security
[2018-09-17T17:27:19,878][INFO ][o.e.d.DiscoveryModule    ] [node-1] using discovery type [zen]
[2018-09-17T17:27:21,289][INFO ][o.e.n.Node               ] [node-1] initialized
[2018-09-17T17:27:21,289][INFO ][o.e.n.Node               ] [node-1] starting ...
[2018-09-17T17:27:21,496][INFO ][o.e.t.TransportService   ] [node-1] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}
[2018-09-17T17:27:24,571][WARN ][o.e.d.z.ZenDiscovery     ] [node-1] not enough master nodes discovered during pinging (found [[Candidate{node={node-1}{D7fISYxgQFahYdTEbqMO4g}{7x0Hu4tQTP-N73j_A073DA}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=8305086464, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true}, clusterStateVersion=-1}]], but needed [2]), pinging again

发现节点 node-2
[2018-09-17T17:28:37,362][INFO ][o.e.c.s.MasterService    ] [node-1] zen-disco-elected-as-master ([1] nodes joined)[, ], reason: new_master {node-1}{D7fISYxgQFahYdTEbqMO4g}{7x0Hu4tQTP-N73j_A073DA}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=8305086464, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true}, added {{node-2}{LNHhP-WPSDaGZJeRHYwBQQ}{zRaTzS0OQkyfCdaRhczR9A}{127.0.0.1}{127.0.0.1:9302}{ml.machine_memory=8305086464, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true},}

发现节点 node-3
[node-1] zen-disco-node-join, reason: added {{node-3}{4rqo1NL0R8KVCAkzI0w4UQ}{s599uwThRGi74YE4WFULIg}{127.0.0.1}{127.0.0.1:9303}{ml.machine_memory=8305086464, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true},}
[2018-09-17T17:29:27,022][INFO ][o.e.c.s.ClusterApplierService] [node-1] added {{node-3}{4rqo1NL0R8KVCAkzI0w4UQ}{s599uwThRGi74YE4WFULIg}{127.0.0.1}{127.0.0.1:9303}{ml.machine_memory=8305086464, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true},}, reason: apply cluster state (from master [master {node-1}{D7fISYxgQFahYdTEbqMO4g}{7x0Hu4tQTP-N73j_A073DA}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=8305086464, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true} committed version [15] source [zen-disco-node-join]])
</code></pre><p>在浏览器中输入如下地址：<br><a href="http://localhost:9201/" target="_blank" rel="noopener">http://localhost:9201/</a><br><a href="http://localhost:9202/" target="_blank" rel="noopener">http://localhost:9202/</a><br><a href="http://localhost:9203/" target="_blank" rel="noopener">http://localhost:9203/</a></p>
<pre><code>{
  &quot;name&quot; : &quot;node-1&quot;,
  &quot;cluster_name&quot; : &quot;hewentian-cluster&quot;,
  &quot;cluster_uuid&quot; : &quot;odUSNw8jS4q-w_Vl66q1qg&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;6.4.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;595516e&quot;,
    &quot;build_date&quot; : &quot;2018-08-17T23:18:47.308994Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;7.4.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}

{
  &quot;name&quot; : &quot;node-2&quot;,
  &quot;cluster_name&quot; : &quot;hewentian-cluster&quot;,
  &quot;cluster_uuid&quot; : &quot;odUSNw8jS4q-w_Vl66q1qg&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;6.4.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;595516e&quot;,
    &quot;build_date&quot; : &quot;2018-08-17T23:18:47.308994Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;7.4.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}

{
  &quot;name&quot; : &quot;node-3&quot;,
  &quot;cluster_name&quot; : &quot;hewentian-cluster&quot;,
  &quot;cluster_uuid&quot; : &quot;odUSNw8jS4q-w_Vl66q1qg&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;6.4.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;595516e&quot;,
    &quot;build_date&quot; : &quot;2018-08-17T23:18:47.308994Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;7.4.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}
</code></pre><p>启动elasticsearch-head，我们就可以看到集群如下图所示：<br><img src="/img/elasticsearch-cluster-1.png" alt="" title="elasticsearch-集群"><br>从图中可以看到<code>node-1</code>已经成为master节点。我们尝试往集群中PUT一些数据，分别往3个不同的端口中PUT数据：</p>
<pre>
curl -XPUT 'http://localhost:9201/twitter/doc/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T13:12:00",
    "message": "Trying out Elasticsearch, so far so good?"
}'

curl -XPUT 'http://localhost:9202/twitter/doc/2?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T14:12:12",
    "message": "Another tweet, will it be indexed?"
}'

curl -XPUT 'http://localhost:9203/twitter/doc/3?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "elastic",
    "post_date": "2010-01-15T01:46:38",
    "message": "Building the site, should be kewl"
}'
</pre>

<p>输出结果如下：</p>
<pre>
{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "1",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "2",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "3",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}
</pre>

<h4 id="我们在elasticsearch-head中查看数据"><a href="#我们在elasticsearch-head中查看数据" class="headerlink" title="我们在elasticsearch-head中查看数据"></a>我们在elasticsearch-head中查看数据</h4><p>elasticsearch-集群状态：<br><img src="/img/elasticsearch-cluster-2.png" alt="" title="elasticsearch-集群状态"></p>
<p>elasticsearch-集群数据<br><img src="/img/elasticsearch-cluster-3.png" alt="" title="elasticsearch-集群数据"></p>
<p>至此，集群搭建结束。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/09/17/elasticsearch-cluster/" data-id="cjogzpsjj0006vv2idjyrqacu" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-elasticsearch-install" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/16/elasticsearch-install/" class="article-date">
  <time datetime="2018-09-16T03:18:34.000Z" itemprop="datePublished">2018-09-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/16/elasticsearch-install/">elasticsearch 单节点安装</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文将说下<code>elasticsearch</code>的单节点安装，我的机器为<code>Ubuntu 16.04 LTS</code>，当前用户为<code>hewentian</code></p>
<p>首先，我们要将<code>elasticsearch</code>安装包下载回来，截止本文写时，它的最新版本为<code>6.4.0</code>，可以在它的<a href="https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.0.tar.gz" target="_blank" rel="noopener">官网</a>下载，当然，我们也可以从这里下载 <a href="https://pan.baidu.com/s/1Rns322X-h0D5pRaqaGPaZQ" title="百度网盘" target="_blank" rel="noopener">elasticsearch-6.4.0.tar.gz</a>，推荐从<code>elasticsearch</code>官网下载最新版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.0.tar.gz</span><br><span class="line">$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.0.tar.gz.sha512</span><br><span class="line"></span><br><span class="line">验证下载文件的完整性，在下载的时候要将 SHA512 文件也下载回来</span><br><span class="line">$ sha512sum -c elasticsearch-6.4.0.tar.gz.sha512 </span><br><span class="line">elasticsearch-6.4.0.tar.gz: OK</span><br><span class="line"></span><br><span class="line">$ tar xzf elasticsearch-6.4.0.tar.gz</span><br></pre></td></tr></table></figure>
<p>对<code>elasticsearch</code>进行设置（目前是单节点，所以也可以不对<code>elasticsearch.yml</code>进行设置，可直接跳过）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearch-6.4.0/config</span><br><span class="line">$ vi elasticsearch.yml 		<span class="comment"># 增加下面的配置</span></span><br><span class="line"></span><br><span class="line">cluster.name: hewentian-cluster	<span class="comment"># 配置集群的名字</span></span><br><span class="line">node.name: node-1		<span class="comment"># 配置集群下的节点的名字</span></span><br><span class="line"></span><br><span class="line">network.host: 127.0.0.1		<span class="comment"># 设置本机IP地址，这里可不设置，但是在集群环境中必须设置。如果在这里指定了IP，则localhost可能无法使用，这个要注意</span></span><br><span class="line"></span><br><span class="line">http.port: 9200			<span class="comment"># 默认也是这个端口</span></span><br><span class="line"></span><br><span class="line">下面的配置保持默认即可，它会将数据和日志保存到elasticsearch-6.4.0目录下的data和logs目录</span><br><span class="line"><span class="comment">#path.data: /path/to/data</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Path to log files:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#path.logs: /path/to/logs</span></span><br></pre></td></tr></table></figure></p>
<p>内存大小的设置，根据机器内存大小而设置，一般不超过系统总内存的一半：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearch-6.4.0/config</span><br><span class="line">$ vi jvm.options</span><br><span class="line"></span><br><span class="line">-Xms1g</span><br><span class="line">-Xmx1g</span><br></pre></td></tr></table></figure></p>
<p>启动<code>elasticsearch</code>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearch-6.4.0/bin</span><br><span class="line">$ ./elasticsearch</span><br></pre></td></tr></table></figure></p>
<p>我们也可以在启动的时候加上参数<code>-d</code>，以后台运行方式启动：<code>./elasticsearch -d</code>。这样单节点版本的<code>elasticsearch</code>就安装完了，在浏览器中输入如下地址：<a href="http://localhost:9200/" target="_blank" rel="noopener">http://localhost:9200/</a></p>
<pre><code>{
&quot;name&quot; : &quot;node-1&quot;,
  &quot;cluster_name&quot; : &quot;hewentian-cluster&quot;,
  &quot;cluster_uuid&quot; : &quot;ihLk1iOlTEis2PkQrLhmLQ&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;6.4.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;595516e&quot;,
    &quot;build_date&quot; : &quot;2018-08-17T23:18:47.308994Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;7.4.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}
</code></pre><p>如果你见到上面的输出，证明安装成功了。</p>
<p>不过，你在安装的过程中，有可能会遇到下面的问题之一：</p>
<pre><code>ERROR: [3] bootstrap checks failed
[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]
[2]: max number of threads [2048] for user [hewentian] is too low, increase to at least [4096]
[3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
</code></pre><p>解决方法如下，就算它不报上面的错误，我们也应该根据机器的性能，对下面的选项作相应配置（下面是根据我机器的情况作的配置）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ su root			<span class="comment"># 必须在 root 下才有权限修改系统配置文件</span></span><br><span class="line">Password: </span><br><span class="line">$ vi /etc/security/limits.conf	<span class="comment"># 添加如下配置</span></span><br><span class="line">* soft nofile 65536		<span class="comment"># 上面第一个错误有提示</span></span><br><span class="line">* hard nofile 131072		<span class="comment"># 一般为 soft nofile 的2倍</span></span><br><span class="line">* soft nproc 4096		<span class="comment"># 这个设置线程数</span></span><br><span class="line">* hard nproc 8192</span><br><span class="line"></span><br><span class="line">$ vi /etc/sysctl.conf		<span class="comment"># 添加如下配置</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"></span><br><span class="line">$ sysctl -p			<span class="comment"># 最后执行这个命令，你会见到如下输出</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">exit</span>				<span class="comment"># 退出 root</span></span><br></pre></td></tr></table></figure></p>
<h4 id="elasticsearch-head的安装"><a href="#elasticsearch-head的安装" class="headerlink" title="elasticsearch-head的安装"></a>elasticsearch-head的安装</h4><p>为了更方便的与elasticsearch交互，我们还要安装<code>elasticsearch-head</code>插件，安装步骤如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/gitHub</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/mobz/elasticsearch-head.git</span><br><span class="line">$ <span class="built_in">cd</span> elasticsearch-head</span><br><span class="line">$ npm install 		<span class="comment"># 这个安装过程可能会报错，但是一般不影响。安装完之后，运行下面的命令即可</span></span><br><span class="line">$ npm run start 	<span class="comment"># 运行此命令，你会看到如下输出</span></span><br><span class="line"></span><br><span class="line">&gt; elasticsearch-head@0.0.0 start /home/hewentian/ProjectD/gitHub/elasticsearch-head</span><br><span class="line">&gt; grunt server</span><br><span class="line"></span><br><span class="line">Running <span class="string">"connect:server"</span> (connect) task</span><br><span class="line">Waiting forever...</span><br><span class="line">Started connect web server on http://localhost:9100</span><br><span class="line"></span><br><span class="line">也可以使用下面这种方式启动</span><br><span class="line">$ nohup npm run start &amp;</span><br></pre></td></tr></table></figure></p>
<p>安装结束之后，可以试着打开这个连接：<a href="http://localhost:9100/" target="_blank" rel="noopener">http://localhost:9100/</a><br>这个连接可以打开，就证明<code>elasticsearch-head</code>安装成功，但是你可能会发现，它无法连上<code>elasticsearch</code>。因为，我们还没有对<code>elasticsearch</code>进行设置：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/elasticsearch-6.4.0/config</span><br><span class="line">$ vi elasticsearch.yml 	<span class="comment"># 增加下面的配置</span></span><br><span class="line"></span><br><span class="line">允许跨域，否则 elasticsearch head 不能访问 elasticsearch</span><br><span class="line">http.cors.enabled: <span class="literal">true</span></span><br><span class="line">http.cors.allow-origin: <span class="string">"*"</span></span><br></pre></td></tr></table></figure></p>
<p>配置好之后，重启<code>elasticsearch</code>，就可以使用<code>elasticsearch-head</code>访问<code>elasticsearch</code>了，如下图所示：<br><img src="/img/elasticsearch-head.png" alt="" title="elasticsearch-head"></p>
<h3 id="elasticsearch使用示例"><a href="#elasticsearch使用示例" class="headerlink" title="elasticsearch使用示例"></a>elasticsearch使用示例</h3><p>使用示例我不打算自已写，因为<code>elasticsearch</code>官方的<code>README.textile</code>已经写得非常详细了。下面的示例摘自<code>elasticsearch-6.4.0/README.textile</code>：<br><strong>下面代码的缩进尽量不要使用tab，要使用空格</strong></p>
<h4 id="Indexing"><a href="#Indexing" class="headerlink" title="Indexing"></a>Indexing</h4><p>Let’s try and index some twitter like information. First, let’s index some tweets (the @twitter@ index will be created automatically):</p>
<pre>
curl -XPUT 'http://localhost:9200/twitter/doc/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T13:12:00",
    "message": "Trying out Elasticsearch, so far so good?"
}'

curl -XPUT 'http://localhost:9200/twitter/doc/2?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T14:12:12",
    "message": "Another tweet, will it be indexed?"
}'

curl -XPUT 'http://localhost:9200/twitter/doc/3?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "elastic",
    "post_date": "2010-01-15T01:46:38",
    "message": "Building the site, should be kewl"
}'
</pre>


<h4 id="Getting"><a href="#Getting" class="headerlink" title="Getting"></a>Getting</h4><p>Now, let’s see if the information was added by GETting it:</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/doc/1?pretty=true'
curl -XGET 'http://localhost:9200/twitter/doc/2?pretty=true'
curl -XGET 'http://localhost:9200/twitter/doc/3?pretty=true'

</pre>

<p>The results show below:</p>
<pre>
{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "1",
  "_version" : 1,
  "found" : true,
  "_source" : {
    "user" : "kimchy",
    "post_date" : "2009-11-15T13:12:00",
    "message" : "Trying out Elasticsearch, so far so good?"
  }
}

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "2",
  "_version" : 1,
  "found" : true,
  "_source" : {
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "Another tweet, will it be indexed?"
  }
}

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "3",
  "_version" : 1,
  "found" : true,
  "_source" : {
    "user" : "elastic",
    "post_date" : "2010-01-15T01:46:38",
    "message" : "Building the site, should be kewl"
  }
}
</pre>


<h4 id="Updating"><a href="#Updating" class="headerlink" title="Updating"></a>Updating</h4><p>The updating operation is the same as Indexing.</p>
<pre>
curl -XPUT 'http://localhost:9200/twitter/doc/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T13:12:00",
    "message": "Trying out Elasticsearch, so far so good? yes"
}'

{
  "_index" : "twitter",
  "_type" : "doc",
  "_id" : "1",
  "_version" : 2,
  "result" : "updated",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 1,
  "_primary_term" : 1
}
</pre>


<h4 id="Deleting"><a href="#Deleting" class="headerlink" title="Deleting"></a>Deleting</h4><p>The deleting operation is also easy.</p>
<pre>
curl -XDELETE 'http://localhost:9200/twitter/doc/1'

{"_index":"twitter","_type":"doc","_id":"1","_version":3,"result":"deleted","_shards":{"total":2,"successful":1,"failed":0},"_seq_no":2,"_primary_term":1}
</pre>

<h4 id="Searching"><a href="#Searching" class="headerlink" title="Searching"></a>Searching</h4><p>Mmm search…, shouldn’t it be elastic?<br>Let’s find all the tweets that @kimchy@ posted:</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/_search?q=user:kimchy&pretty=true'

{
  "took" : 42,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 0.2876821,
    "hits" : [
      {
        "_index" : "twitter",
        "_type" : "doc",
        "_id" : "2",
        "_score" : 0.2876821,
        "_source" : {
          "user" : "kimchy",
          "post_date" : "2009-11-15T14:12:12",
          "message" : "Another tweet, will it be indexed?"
        }
      },
      {
        "_index" : "twitter",
        "_type" : "doc",
        "_id" : "1",
        "_score" : 0.2876821,
        "_source" : {
          "user" : "kimchy",
          "post_date" : "2009-11-15T13:12:00",
          "message" : "Trying out Elasticsearch, so far so good?"
        }
      }
    ]
  }
}
</pre>

<p>We can also use the JSON query language Elasticsearch provides instead of a query string:</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "match" : { "user": "kimchy" }
    }
}'
</pre>

<p>Just for kicks, let’s get all the documents stored (we should see the tweet from @elastic@ as well):</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "match_all" : {}
    }
}'
</pre>

<p>We can also do range search (the @post_date@ was automatically identified as date)</p>
<pre>
curl -XGET 'http://localhost:9200/twitter/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "range" : {
            "post_date" : { "from" : "2009-11-15T13:00:00", "to" : "2009-11-15T14:00:00" }
        }
    }
}'
</pre>

<p>There are many more options to perform search, after all, it’s a search product no? All the familiar Lucene queries are available through the JSON query language, or through the query parser.</p>
<h4 id="Multi-Tenant-Indices-and-Types"><a href="#Multi-Tenant-Indices-and-Types" class="headerlink" title="Multi Tenant - Indices and Types"></a>Multi Tenant - Indices and Types</h4><p>Man, that twitter index might get big (in this case, index size == valuation). Let’s see if we can structure our twitter system a bit differently in order to support such large amounts of data.</p>
<p>Elasticsearch supports multiple indices. In the previous example we used an index called @twitter@ that stored tweets for every user.</p>
<p>Another way to define our simple twitter system is to have a different index per user (note, though that each index has an overhead). Here is the indexing curl’s in this case:</p>
<pre>
curl -XPUT 'http://localhost:9200/kimchy/doc/1?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T13:12:00",
    "message": "Trying out Elasticsearch, so far so good?"
}'

curl -XPUT 'http://localhost:9200/kimchy/doc/2?pretty' -H 'Content-Type: application/json' -d '
{
    "user": "kimchy",
    "post_date": "2009-11-15T14:12:12",
    "message": "Another tweet, will it be indexed?"
}'
</pre>

<p>The above will index information into the @kimchy@ index. Each user will get their own special index.</p>
<p>Complete control on the index level is allowed. As an example, in the above case, we would want to change from the default 5 shards with 1 replica per index, to only 1 shard with 1 replica per index (== per twitter user). Here is how this can be done (the configuration can be in yaml as well):</p>
<pre>
curl -XPUT http://localhost:9200/another_user?pretty -H 'Content-Type: application/json' -d '
{
    "index" : {
        "number_of_shards" : 1,
        "number_of_replicas" : 1
    }
}'
</pre>

<p>Search (and similar operations) are multi index aware. This means that we can easily search on more than one<br>index (twitter user), for example:</p>
<pre>
curl -XGET 'http://localhost:9200/kimchy,another_user/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "match_all" : {}
    }
}'
</pre>

<p>Or on all the indices:</p>
<pre>
curl -XGET 'http://localhost:9200/_search?pretty=true' -H 'Content-Type: application/json' -d '
{
    "query" : {
        "match_all" : {}
    }
}'
</pre>

<p>{One liner teaser}: And the cool part about that? You can easily search on multiple twitter users (indices), with different boost levels per user (index), making social search so much simpler (results from my friends rank higher than results from friends of my friends).</p>
<h4 id="Cat-Index"><a href="#Cat-Index" class="headerlink" title="Cat Index"></a>Cat Index</h4><pre>
curl -XGET 'http://localhost:9200/_cat/indices?v'

health status index   uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   twitter 1aZo0hSfRkKG1INAEZgpnQ   5   1          2            0       14kb           14kb
yellow open   music   ytI7cirvQXOi1hsrvAMGGA   5   1          0            0      1.2kb          1.2kb
</pre>



      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/09/16/elasticsearch-install/" data-id="cjogzpsjn0008vv2ids2b5wzf" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-redis-note" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/12/redis-note/" class="article-date">
  <time datetime="2018-09-12T00:54:32.000Z" itemprop="datePublished">2018-09-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/12/redis-note/">redis 学习笔记</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>首先，你必须有一台<code>redis</code>服务器可以使用，如果还没安装，可以参考我的上一篇 <a href="../../../../2018/08/07/redis-install/">redis 的安装使用</a></p>
<p>使用JAVA API来操作Redis的例子可以在这里找到：<a href="https://github.com/hewentian/studyResource/blob/master/src/main/java/com/hewentian/util/RedisUtil.java">RedisUtil.java</a>、<a href="https://github.com/hewentian/studyResource/blob/master/src/main/java/com/hewentian/redis/RedisDemo.java">RedisDemo.java</a></p>
<p>部分笔记摘自《Redis 实战》，它总结得很好。</p>
<p>Redis默认16个数据库，并以数字为索引，从0开始到15，可以手工修改这个配置，增加数量。登录的时候，默认为0库。</p>
<h4 id="Redis与其他数据库的对比"><a href="#Redis与其他数据库的对比" class="headerlink" title="Redis与其他数据库的对比"></a>Redis与其他数据库的对比</h4><p>  高性能键值缓存服务器<code>memcached</code>也经常被拿来与<code>Redis</code>进行比较：这两者都可以用于存储键值映射，彼此的性能也相关无几，但是<code>Redis</code>能够自动以两种不同的方式将数据写入硬盘，并且<code>Redis</code>除了能存储普通的字符串之外，还可以存储其他4种数据结构，而<code>memcached</code>只能存储普通的字符串键。这些不同之处使得<code>Redis</code>可以用于解决更为广泛的问题，并且既可以用作主数据库(primary database)使用，又可以作为其他存储系统的辅助数据库(auxiliary database)使用。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th style="text-align:left">类型</th>
<th style="text-align:left">数据存储选项</th>
<th style="text-align:left">查询类型</th>
<th style="text-align:left">附加功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>Redis</td>
<td style="text-align:left">使用内存存储的非关系数据库</td>
<td style="text-align:left">字符串、列表、集合、散列表、有序集合</td>
<td style="text-align:left">每种数据类型都有自已的专属命令，另外还有批量操作(bulk operation)和不完全(partial)的事务支持</td>
<td style="text-align:left">发布与订阅，主从复制(master/slave replication)，持久化，脚本(存储过程，stored procedure)</td>
</tr>
<tr>
<td>memcached</td>
<td style="text-align:left">使用内存存储的键值缓存</td>
<td style="text-align:left">键值之间的映射</td>
<td style="text-align:left">创建命令、读取命令、更新命令、删除命令以及其他几个命令</td>
<td style="text-align:left">为提升性能而设的多线程服务器</td>
</tr>
<tr>
<td>Mysql</td>
<td style="text-align:left">关系数据库</td>
<td style="text-align:left">每个数据库可以包含多个表，每个表可以包含多个行；可以处理多个表的视图(view)；支持空间(spatial)和第三方扩展</td>
<td style="text-align:left">SELECT、INSERT、UPDATE、DELETE、函数、存储过程</td>
<td style="text-align:left">支持ACID性质(需要使用InnoDB)，主从复制，主主复制(master/master replication)</td>
</tr>
<tr>
<td>PostgreSQL</td>
<td style="text-align:left">关系数据库</td>
<td style="text-align:left">每个数据库可以包含多个表，每个表可以包含多个行；可以处理多个表的视图(view)；支持空间(spatial)和第三方扩展；支持可定制类型</td>
<td style="text-align:left">SELECT、INSERT、UPDATE、DELETE、内置函数、自定义存储过程</td>
<td style="text-align:left">支持ACID性质，主从复制，由第三方支持的多主复制(multi-master replication)</td>
</tr>
<tr>
<td>MongoDB</td>
<td style="text-align:left">使用硬盘存储的非关系文档存储</td>
<td style="text-align:left">每个数据库可以包含多个表，每个表可以包含多个无schema(schema-less)的BSON文档</td>
<td style="text-align:left">创建命令、读取命令、更新命令、删除命令、条件查询命令等</td>
<td style="text-align:left">支持 map-reduce 操作，主从复制，分片，空间索引(spatial index)</td>
</tr>
</tbody>
</table>
<h4 id="Redis提供的5种结构"><a href="#Redis提供的5种结构" class="headerlink" title="Redis提供的5种结构"></a>Redis提供的5种结构</h4><table>
<thead>
<tr>
<th>结构类型</th>
<th style="text-align:left">结构存储的值</th>
<th style="text-align:left">结构的读写能力</th>
</tr>
</thead>
<tbody>
<tr>
<td>STRING</td>
<td style="text-align:left">可以是字符串、整数或者浮点数</td>
<td style="text-align:left">对整个字符串或者字符串的其中一部分执行操作，对整数和浮点数执行自增或者自减操作</td>
</tr>
<tr>
<td>LIST</td>
<td style="text-align:left">一个链表，链表上的每个节点都包含了一个字符串</td>
<td style="text-align:left">从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪；读取单个或者多个元素；根据值查找或者移除元素</td>
</tr>
<tr>
<td>SET</td>
<td style="text-align:left">包含字符串的无序收集器，并且被包含的每个字符串都是独一无二、各不相同的</td>
<td style="text-align:left">添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素</td>
</tr>
<tr>
<td>HASH</td>
<td style="text-align:left">包含键值对的无序散列表</td>
<td style="text-align:left">添加、获取、移除单个键值对；获取所有键值对</td>
</tr>
<tr>
<td>ZSET(有序集合)</td>
<td style="text-align:left">字符串成员与浮点数分值之间的有序映射，元素的排列顺序由分值的大小决定</td>
<td style="text-align:left">添加、获取、删除单个元素；根据分值范围或者成员来获取元素</td>
</tr>
</tbody>
</table>
<p>  在实际中最好还是让主服务器只使用50%~65%的内存，留下30%~45%的内存用于执行BGSAVE命令和创建记录写命令的缓冲区。</p>
<p>  当所有成员的分值都相同时，有序集合将根据成员的名字来进行排序；而当所有成员的分值都是0的时候，成员将按照字符串的二进制顺序进行排序。</p>
<p>  对于大部分数据库来说，插入行操作的执行速度非常快（插入行只会在硬盘文件末尾进行写入）。不过，对表里面的行进行更新却是一个速度相当慢的操作，因为这种更新除了会引起一次随机读(random read)之外，还可能会引起一次随机写(random write)。</p>
<p>使用cookie实现购物车–也就是将整个购物车都存储到cookie里面的做法非常常见，这种做法的一大优点是无须对数据库进行写入就可以实现购物车功能，而缺点则是程序需要重新解析和验证cookie，确保cookie的格式正确，并且包含的商品都是真正可购买的商品。cookie购物车还有一个缺点：因为浏览器每次发送请求都会连cookie一起发送，所以如果购物车cookie的体积比较大，那么请求发送和处理的速度可能会有所降低。</p>
<p>如果用户对一个不存在的键或者一个保存了空串的键执行自增或者自减操作，那么Redis在执行操作时会将这个键的值当作是0来处理。如果用户尝试对一个值无法被解释为整数或者浮点数的字符串键执行自增或者自减操作，那么Redis将向用户返回一个错误。</p>
<p>Redis不支持嵌套结构特性</p>
<h4 id="Redis的基本事务"><a href="#Redis的基本事务" class="headerlink" title="Redis的基本事务"></a>Redis的基本事务</h4><p>  Redis的基本事务(basic transaction)需要用到MULTI命令和EXEC命令，这种事务可以让一个客户端在不被其他客户端打断的情况下执行多个命令。和关系数据库那种可以在执行的过程中进行回滚(rollback)的事务不同，在Redis里面，被MULTI命令和EXEC命令包围的所有命令会一个接一个地执行，直到所有命令都执行完毕为止。当一个事务执行完毕之后，Redis才会处理其他客户端的命令。<br>  要在Redis里面执行事务，我们首先需要执行MULTI命令，然后输入那些我们想要在事务里面执行的命令，最后再执行EXEC命令。当Redis从一个客户端那里接收到MULTI命令时，Redis会将这个客户端之后发送的所有命令都放入到一个队列里面，直到这个客户端发送EXEC命令为止，然后Redis就会在不被打断的情况下，一个接一个地执行存储在队列里面的命令。从语义上来说，Redis事务在Python客户端上面是由流水线(pipeline)实现的：对连接对象调用pipeline()方法将创建一个事务，在一切正常的情况下，客户端会自动地使用MULTI和EXEC包裹起用户输入的多个命令。此外，为了减少Redis与客户端之间的通信往返次数，提升执行多个命令时的性能，Python的Redis客户端会存储起事务包含的多个命令，然后在事务执行时一次性地将所有命令都发送给Redis。</p>
<h4 id="持久化选项"><a href="#持久化选项" class="headerlink" title="持久化选项"></a>持久化选项</h4><p>  Redis提供了两种不同的持久化方法来将数据存储到硬盘里面。一种方法叫快照(snapshotting)，它可以将存在于某一时刻的所有数据都写入硬盘里面。另一种方法叫只追加文件(append-only file, AOF)，它会在执行写命令时，将被执行的写命令复制到硬盘里面。这两种持久化方法既可以同时使用，又可以单独使用，在某些情况下甚至可以两种方法都不使用。<br>  为了防止Redis因为创建子进程而出现停顿，我们可以考虑关闭自动保存，转而通过手动发送BGSAVE或者SAVE来进行持久化。手动发送BGSAVE一样会引起停顿，唯一不同的是用户可以通过手动发送BGSAVE命令来控制停顿出现的时间。另一方面，虽然SAVE会一直阻塞Redis直到快照生成完毕，但是因为它不需要创建子进程，所以就不会像BGSAVE一样因为创建子进程而导致Redis停顿；并且因为没有子进程在争抢资源，所以SAVE创建快照的速度会比BGSAVE创建快照的速度要来得更快一些。</p>
<h4 id="创建快照的办法有以下几种"><a href="#创建快照的办法有以下几种" class="headerlink" title="创建快照的办法有以下几种"></a>创建快照的办法有以下几种</h4><ol>
<li>客户端可以通过向Redis发送BGSAVE命令来创建一个快照；</li>
<li>客户端还可以通过向Redis发送SAVE命令来创建一个快照，接到SAVE命令的Redis服务器在快照创建完毕之前将不再响应任何其他命令；</li>
<li>用户设置save配置选项；</li>
<li>当Redis通过SHUTDOWN命令接收到关闭服务器的请求时，或者接收到标准TERM信号时，会执行一个SAVE命令；</li>
<li>当一个Redis服务器连接另一个Redis服务器，并向对方发送SYNC命令来开始一次复制操作的时候，如果主服务器目前没有在执行BGSAVE操作，或者主服务器并非刚刚执行完BGSAVE操作，那么主服务器就会执行BGSAVE命令。</li>
</ol>
<p>在只使用快照持久化来保存数据时，一定要记住：如果系统真的发生崩溃，用户将丢失最近一次生成快照之后更改的所有数据。因此，快照持久化只适用于那些即使丢失一部分数据也不会造成问题的应用程序。</p>
<p>  当Redis存储的数据量只有几个GB的时候，使用快照来保存数据是没有问题的。Redis会创建子进程并将数据保存到硬盘里面，生成快照所需的时间比你读这句话所需的时间还要短。但随着Redis占用的内存越来越多，BGSAVE在创建子进程时耗费的时间也会越来越多。如果Redis的内存占用量达到数十个GB，并且剩余的空闲内存并不多，或者Redis运行在虚拟机上面，那么执行BGSAVE可能会导致系统长时间地停顿，也可能引发系统大量地使用虚拟内存，从而导致Redis的性能降低至无法使用的程度。</p>
<p>  AOF持久化会将被执行的写命令写到AOF文件的末尾，以此来记录数据发生的变化。因此，Redis只要从头到尾重新执行一次AOF文件包含的所有写命令，就可以恢复AOF文件所记录的数据集。通过<code>appendonly yes</code>配置选项来打开。</p>
<p>  Redis每秒同步一次AOF文件时的性能和不使用任何持久化特性时的性能相关无几，而通过每秒同步一次AOF文件，Redis可以保证，即使出现系统崩溃，用户也最多只会丢失一秒之内产生的数据。</p>
<p>  因为Redis会不断地将被执行的写命令记录到AOF文件里面，所以随着Redis不断运行，AOF文件的体积也会不断增长，在极端情况下，体积不断增大的AOF文件甚至可能会用完硬盘的所有可用空间。还有另一个问题就是，因为Redis在重启之后需要通过重新执行AOF文件记录的所有写命令来还原数据集，所以如果AOF文件的体积非常大，那么还原操作执行的时间就可能会非常长。为了解决AOF文件体积不断增大的问题，用户可以向Redis发送BGREWRITEAOF命令，这个命令会通过移除AOF文件中的冗余命令来重写(rewrite)AOF文件，使AOF文件的体积变得尽可能地小。</p>
<p>  关系数据库通常会使用一个主服务器(master)向多个从服务器(slave)发送更新，并使用从服务器来处理所有读请求。在Redis中开启从服务器所必须的选项只有<code>slaveof</code>一个。通过向从服务器发送<code>SLAVEOF no one</code>命令，我们可以让这个从服务器断开与主服务器的连接。因为Redis的主服务器和从服务器并没有特别不同的地方，所以从服务器也可以拥有自已的从服务器，并由此形成主从链(master/slave chaining)，如下图：<br><img src="/img/redis-master-slave-chaining.png" alt=""></p>
<p>  解决从服务器重同步(resync)问题的其中一个方法，就是减少主服务器需要传送给从服务器的数据数量，这可以通过构建像上图所示的树状复制中间层来完成。除了构建树状的从服务器群组之外，解决从服务器重同步问题的另一个方法就是对网络连接进行压缩，从而减少需要传送的数据量。一些Redis用户就发现使用带压缩的SSH隧道(tunnel)进行连接可以明显地降低带宽占用，如果使用这个方法，记得使用SSH提供的选项来让SSH连接在断线后自动进行连接。</p>
<p>  提升Redis读取能力的最简单方法，就是添加只读从服务器。在使用只读从服务器的时候，请务必记得只对Redis主服务器进行写入。在默认情况下，尝试对一个被配置为从服务器的Redis服务器进行写入将引发一个错误（就算这个从服务器是其他从服务器的主服务器，也是如此）。不过，可以通过设置配置选项使从服务器也能执行写入操作，不过由于这一功能通常都处于关闭状态，所以对从服务器进行写入一般都会引发错误。使用多个Redis从服务器处理读查询时可能会遇到的最棘手的问题，就是主服务器临时下线或者永久下线。</p>
<p>  Redis Sentinel可以配合Redis的复制功能使用，并对下线的主服务器进行故障转移。</p>
<h4 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h4><p>  一般来说，在对数据进行“加锁”时，程序首先需要通过获取(acquire)锁来得到对数据进行排他性访问的能力，然后才能对数据进行一系列的操作，最后还要将锁释放(release)给其他程序。对于能够被多个线程访问的共享内存数据结构来说，这种“先获取锁，然后执行操作，最后释放锁”的动作非常常见。Redis使用WATCH命令来代替对数据进行加锁，因为WATCH只会在数据被其他客户端抢先修改了的情况下通知执行了这个命令的客户端，而不会阻止其他客户端对数据进行修改，所以这个命令被称为乐观锁(optimistic locking)。</p>
<p>  分布式锁也有类似的“首先获取锁，然后执行操作，最后释放锁”动作，但这种锁既不是给同一个进程中的多个线程使用，也不是给同一台机器上的多个进程使用，而是由不同机器上的不同Redis客户端进行获取和释放锁的。</p>
<p>  我们没有直接使用操作系统级别的锁、编程语言级别的锁，或者其他各式各样的锁，而是选择了花费大量时间去使用Redis构建锁，这其中一个原因和范围有关：为了对Redis存储的数据进行排他性访问，客户端需要访问一个锁，这个锁必须定义在一个可以让所有客户端都看得见的范围之内，而这个范围就是Redis本身，因此我们需要把锁构建在Redis里面。另一方面，虽然Redis提供SETNX命令确实具有基本的加锁功能，但它的功能并不完整，并且也不具备分布式锁常见的一些高级特性，所以我们还是需要自已动手来构建分布式锁。</p>
<p>  WATCH、MULTI和EXEC组成的事务并不具有可扩展性，原因在于程序在尝试完成一个事务的时候，可能会因为事务执行失败而反复地进行重试。保证数据的正确性是一件非常重要的事情，但使用WATCH命令的做法并不完美 。为了解决这个问题，我们将使用锁。</p>
<p>  因为客户端即使在使用锁的过程中也可能会因为这样或那样的原因而下线，所以为了防止客户端在取得锁之后崩溃，并导致锁一直处于“已被获取”的状态，最终版的锁实现将带有超时限制特性：如果获得锁的进程未能在指定的时限内完成操作，那么锁将自动被释放。下面列出了一些导致锁出现不正确实行为的原因，也及锁在不正确运行时的症状：</p>
<ol>
<li>持有锁的进程因为操作时间过长而导致锁被自动释放，但进程本身并不知晓这一点，甚至还可能会错误地释放掉了其他进程持有的锁；</li>
<li>一个持有锁并打算执行长时间操作的进程已经崩溃，但其他想要获取锁的进程不知道哪个进程持有着锁，也无法检测出持有锁的进程已经崩溃，只能白白地浪费时间等待锁被释放；</li>
<li>在一个进程持有的锁过期之后，其他多个进程同时尝试去获取锁，并且都获得了锁；</li>
<li>上面提到的第一种情况和第三种情况同时出现，导致有多个进程获得了锁，而每个进程都以为自已是唯一一个获得锁的进程。</li>
</ol>
<p>在高负载情况下，使用锁可以减少重试次数、降低延迟时间、提升性能并将加锁的粒度调整至合适的大小。</p>
<p>一般来说，当程序使用一个来自Redis的值去构建另一个将要被添加到Redis里面的值时，就需要使用锁或者由WATCH、MULTI和EXEC组成的事务来消除竞争条件。</p>
<h4 id="计数信号量"><a href="#计数信号量" class="headerlink" title="计数信号量"></a>计数信号量</h4><p>  计数信号量是一种锁，它可以让用户限制一项资源最多能够同时被多少个进程访问，通常用于限定能够同时使用的资源数量。你可以把我们在前一节创建的锁看作是只能被一个进程访问的信号量。计数信号量和其他锁的区别在于，当客户端获取锁失败的时候，客户端通常会选择进行等待；而当客户端获取计数信号量失败的时候，客户端通常会选择立即返回失败结果。</p>
<p>  以下是之前介绍过的各个信号量实现的优缺点：</p>
<ol>
<li>如果你对于使用系统时钟没有意见，也不需要对信号量进行刷新，并且能够接受信号量的数量偶尔超过限制，那么可以使用我们给出的第一个信号量实现；</li>
<li>如果你只信任差距在一两秒之间的系统时钟，但仍然能够接受信号量的数量偶尔超过限制，那么你可以使用第二个信号量实现；</li>
<li>如果你希望信号量一直都具有正确的行为，那么可以使用带锁的信号量实现来保证正确性。</li>
</ol>
<h4 id="消息拉取"><a href="#消息拉取" class="headerlink" title="消息拉取"></a>消息拉取</h4><p>  两个或多个客户端在互相发送和接收消息的时候，通常会使用以下两种方法来传递消息。第一种被称为消息推送(push messaging)，也就是由发送者来确保所有接收者已经成功接收到了消息。Redis内置了用于进行消息推送的PUBLISH命令和SUBSCRIBE命令。这两个命令有个缺陷：客户端必须一直在线才能接收到消息，断线可能会导致客户端丢失消息。第二种方法被称为消息拉取(pull messaging)，这种方法要求接收者自已去获取存储在某种邮箱(mailbox)里面的消息。</p>
<h4 id="索引相关"><a href="#索引相关" class="headerlink" title="索引相关"></a>索引相关</h4><p>  从文档里面提取单词的过程通常被称为语法分析(parsing)和标记化(tokenization)，这个过程可以产生出一系列用于标识文档的标记(token)，标记有时候又被称为单词(word)。标记化的一个常见的附加步骤，就是移除内容中的非用词(stop word)。非用词就是那些在文档中频繁出现但是却没有提供相应信息量的单词，对这些单词进行搜索将返回大量无用的结果。移除非用词不仅可以提高搜索性能，还可以减少索引的体积。<br>  用户有些时候可能会想要使用多个具有相同意思的单词进行搜索，并把它们看作是同一个单词，我们把这样的单词称为同义词。<br>  搜索程序在取得多个文档之后，通常还需要根据每个文档的重要性对它们进行排序–搜索领域把这一问题称为关联度计算问题。</p>
<h4 id="广告相关"><a href="#广告相关" class="headerlink" title="广告相关"></a>广告相关</h4><p>  广告索引操作的特别之处在于它返回的不是一组广告或者一组搜索结果，而是单个广告；并且被索引的广告通常都拥有像位置、年龄或者性别这类必须的定向参数。</p>
<p>  Web页面上展示的广告主要有3种类型：按展示次数计费(cost per view)、按点击次数计费(cost per click)和按动作执行次数计费(cost per action)。按展示次数计费的广告又称为CPM广告或按千次计费(cost per mile)广告，这种广告每展示1000次就需要收取固定的费用。按点击计费的广告又称为CPC广告，这种广告根据被点击的次数收取固定的费用。按动作执行次数计费的广告又称为CPA广告，这种广告根据用户在广告的目的地网站上执行的动作收取不同的费用。</p>
<p>  让广告的价格保持一致：为了尽可能地简化广告价格的计算方式，程序将对所有类型的广告进行转换，使得它们的价格可以基于每千次展示进行计算，产生出一个估算CPM(estimated CPM)，简称eCPM。对于CPM广告来说，因为这种广告已经给出了CPM价格，所以程序只要直接把它的CPM用作eCPM就可以了。至于CPC广告和CPA广告，程序则需要根据相应的规则为它们计算出eCPM。</p>
<h4 id="优化Redis"><a href="#优化Redis" class="headerlink" title="优化Redis"></a>优化Redis</h4><p>  降低Redis的内存占用有助于减少创建快照和加载快照所需的时间、提升载入AOF文件和重写AOF文件时的效率、缩短从服务器进行同步所需的时间，并且能让Redis存储更多的数据而无需添加额外的硬件。</p>
<p>  在列表、散列和有序集合的长度较短或者体积较小的时候，Redis可以选择使用一种名为压缩列表(ziplist)的紧凑存储方式来存储这些结构。压缩列表会以序列化的方式存储数据，这些序列化数据每次被读取的时候都要进行解码，每次被写入的时候也要进行局部的重新编码，并且可能需要对内存里面的数据进行移动。</p>
<h4 id="不同结构关于使用压缩列表表示的配置选项（我安装的是-4-0-11-版本），配置文件位于-REDIS-HOME-redis-conf"><a href="#不同结构关于使用压缩列表表示的配置选项（我安装的是-4-0-11-版本），配置文件位于-REDIS-HOME-redis-conf" class="headerlink" title="不同结构关于使用压缩列表表示的配置选项（我安装的是 4.0.11 版本），配置文件位于{REDIS_HOME}/redis.conf"></a>不同结构关于使用压缩列表表示的配置选项（我安装的是 4.0.11 版本），配置文件位于<code>{REDIS_HOME}/redis.conf</code></h4><pre><code># Hashes are encoded using a memory efficient data structure when they have a
# small number of entries, and the biggest entry does not exceed a given
# threshold. These thresholds can be configured using the following directives.
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# Lists are also encoded in a special way to save a lot of space.
# The number of entries allowed per internal list node can be specified
# as a fixed maximum size or a maximum number of elements.
# For a fixed maximum size, use -5 through -1, meaning:
# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads
# -4: max size: 32 Kb  &lt;-- not recommended
# -3: max size: 16 Kb  &lt;-- probably not recommended
# -2: max size: 8 Kb   &lt;-- good
# -1: max size: 4 Kb   &lt;-- good
# Positive numbers mean store up to _exactly_ that number of elements
# per list node.
# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),
# but if your use case is unique, adjust the settings as necessary.
list-max-ziplist-size -2

# Sets have a special encoding in just one case: when a set is composed
# of just strings that happen to be integers in radix 10 in the range
# of 64 bit signed integers.
# The following configuration setting sets the limit in the size of the
# set in order to use this special memory saving encoding.
set-max-intset-entries 512

# Similarly to hashes and lists, sorted sets are also specially encoded in
# order to save a lot of space. This encoding is only used when the length and
# elements of a sorted set are below the following limits:
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
</code></pre><p>说明：</p>
<ol>
<li>entries选项说明散列、集合和有序集合在被编码为压缩列表的情况下，允许包含的最大元素数量；</li>
<li>value选项则说明了压缩列表每个节点的最大体积是多少个字节；</li>
<li>当上述两个选项的限制条件中的任意一个被突破的时候，Redis就会将相应的列表、散列或是有序集合从压缩列表编码转换为其他结构，而内存占用也会因此而增加；</li>
<li>当压缩列表被转换为普通的结构之后，即使结构将来重新满足配置选项设置的限制条件，结构也不会重新转换回压缩列表；</li>
<li>如果整数包含的所有成员都可以被解释为十进制整数，而这些整数又处于平台的有符号整数范围之内，并且集合成员的数量又足够少的话（上面有配置），那么Redis就会以有序整数数组的方式存储集合，这种存储方式又被称为整数集合(intset)。以有序数组的方式存储集合不仅可以降低内存消耗，还可以提升所有标准集合的执行速度。</li>
</ol>
<p>缺点：读写一个长度较大的压缩列表可能会给性能带来负面的影响，随着紧凑结构的体积变得越来越大，操作这些结构的速度也会变得越来越慢。</p>
<h4 id="让键名保持简短"><a href="#让键名保持简短" class="headerlink" title="让键名保持简短"></a>让键名保持简短</h4><p>  到目前为止尚未提到的一件事，就是减少键长度的作用，这里所说的“键”包括所有数据库键、散列的域、集合和有序集合的成员以及所有列表的节点，键的长度越长，Redis需要存储的数据也就越多。</p>
<h4 id="分片结构"><a href="#分片结构" class="headerlink" title="分片结构"></a>分片结构</h4><p>  分片本质上就是基于某些简单的规则将数据划分为更小的部分，然后根据数据所属的部分来决定将数据发送到哪个位置上面。</p>
<h4 id="使用Lua来扩展Redis"><a href="#使用Lua来扩展Redis" class="headerlink" title="使用Lua来扩展Redis"></a>使用Lua来扩展Redis</h4><p>  使用Lua编程语言进行的服务器端脚本编程功能，这个功能可以让用户直接在Redis内部执行各种操作，从而达到简化代码并提高性能的作用。将脚本载入Redis需要用到一个名为<code>SCRIPT LOAD</code>的命令，这个命令接受一个字符串格式的Lua脚本为参数，它会把脚本存储起来等待之后使用，然后返回被存储脚本的SHA1校验和。之后，用户只要调用<code>EVALSHA</code>命令，并输入脚本的SHA1校验和以及脚本所需的全部参数就可以调用之前存储的脚本。</p>
<p>  Lua版本的锁实现减少了加锁时所需的通信往返次数，所以Lua版本的锁实现在尝试获取锁时的速度比原版的锁要快得多。虽然Lua脚本可以提供巨大的性能优势，并且能在一些情况下大幅地简化代码，但是我们也要记住，运行在Redis内部的Lua脚本只能访问位于Lua脚本之内或者Redis数据库之内的数据，而锁或<code>WATCH/MULTI/EXEC</code>事务并没有这一限制。</p>
<p>  Redis在将数据库持久化到硬盘的时候，需要用到fork系统调用，而Windows并不支持这个调用。在缺少fork调用的情况下，Redis在执行持久化操作期间就只能够阻塞所有客户端，直到持久化操作执行完毕为止。</p>
<p>查看一个对象的类型可以使用<code>DEBUG OBJECT</code>命令</p>
<pre><code>127.0.0.1:6379&gt; rpush test a b c d
(integer) 4
127.0.0.1:6379&gt; DEBUG OBJECT test
Value at:0x7f6160c774e0 refcount:1 encoding:quicklist serializedlength:25 lru:9577083 lru_seconds_idle:44 ql_nodes:1 ql_avg_node:4.00 ql_ziplist_max:-2 ql_compressed:0 ql_uncompressed_size:23
127.0.0.1:6379&gt;
</code></pre><h3 id="redis命令行查看中文显示乱码"><a href="#redis命令行查看中文显示乱码" class="headerlink" title="redis命令行查看中文显示乱码"></a>redis命令行查看中文显示乱码</h3><p>Redis在使用命令行操作时，如果查看内容中包含中文，会显示16进制的字符串<code>\xe4\xbf\xa1\xe9\x98\xb3\xe5\xb8\x82\</code>，为了正确显示中文，在启动客启端的时候，加上<code>--raw</code>参数即可：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ./redis-cli -h 127.0.0.1 --raw</span><br><span class="line">127.0.0.1:6379&gt; get city</span><br><span class="line">广州</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/09/12/redis-note/" data-id="cjogzpsn3002evv2itt74ibza" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/redis/">redis</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-redis-master-slave" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/14/redis-master-slave/" class="article-date">
  <time datetime="2018-08-14T06:53:19.000Z" itemprop="datePublished">2018-08-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/14/redis-master-slave/">redis 主从配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>要配置主从，我们必须安装两台<code>redis</code>：主服务器为<code>master</code>，从服务器为<code>slave</code>。安装步骤请参考我的上一篇 <a href="../../../../2018/08/07/redis-install/">redis 的安装使用</a></p>
<h3 id="我们在一台机器上面配置主从，多台的配置是一样的，只要修改下IP和PORT即可。以我们上一篇安装好的一台redis为基础，它的安装路径为：-home-hewentian-ProjectD-redis-4-0-11"><a href="#我们在一台机器上面配置主从，多台的配置是一样的，只要修改下IP和PORT即可。以我们上一篇安装好的一台redis为基础，它的安装路径为：-home-hewentian-ProjectD-redis-4-0-11" class="headerlink" title="我们在一台机器上面配置主从，多台的配置是一样的，只要修改下IP和PORT即可。以我们上一篇安装好的一台redis为基础，它的安装路径为：/home/hewentian/ProjectD/redis-4.0.11"></a>我们在一台机器上面配置主从，多台的配置是一样的，只要修改下<code>IP</code>和<code>PORT</code>即可。以我们上一篇安装好的一台<code>redis</code>为基础，它的安装路径为：<code>/home/hewentian/ProjectD/redis-4.0.11</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD</span><br><span class="line">$ mv redis-4.0.11 redis-4.0.11_master</span><br><span class="line">$ cp -r redis-4.0.11_master/ redis-4.0.11_slave/</span><br></pre></td></tr></table></figure>
<p><code>master</code>服务器为：<code>/home/hewentian/ProjectD/redis-4.0.11_master</code><br><code>slave</code>服务器为：<code>/home/hewentian/ProjectD/redis-4.0.11_slave</code></p>
<h3 id="master服务器使用默认端口6379，所以不用配置。下面我们配置slave服务器："><a href="#master服务器使用默认端口6379，所以不用配置。下面我们配置slave服务器：" class="headerlink" title="master服务器使用默认端口6379，所以不用配置。下面我们配置slave服务器："></a><code>master</code>服务器使用默认端口<code>6379</code>，所以不用配置。下面我们配置<code>slave</code>服务器：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_slave/</span><br><span class="line">$ vi redis.conf</span><br><span class="line"></span><br><span class="line">// 将默认端口改为6380，并加上 slaveof 127.0.0.1 6379 和 pidfile，在文件里面改动如下：</span><br><span class="line">port 6380</span><br><span class="line">slaveof 127.0.0.1 6379</span><br><span class="line">pidfile /var/run/redis_6380.pid</span><br></pre></td></tr></table></figure>
<p>保存文件并退出，<code>slave</code>服务器配置完成。</p>
<h3 id="接着我们启动master和slave服务器"><a href="#接着我们启动master和slave服务器" class="headerlink" title="接着我们启动master和slave服务器"></a>接着我们启动<code>master</code>和<code>slave</code>服务器</h3><p>启动<code>master</code>服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_master/src/</span><br><span class="line">$ ./redis-server /home/hewentian/ProjectD/redis-4.0.11_master/redis.conf</span><br></pre></td></tr></table></figure></p>
<p>启动<code>slave</code>服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_slave/src/</span><br><span class="line">$ ./redis-server /home/hewentian/ProjectD/redis-4.0.11_slave/redis.conf</span><br></pre></td></tr></table></figure></p>
<p>在<code>master</code>服务器窗口中，可以看到如下信息：</p>
<pre><code>1514:M 14 Aug 15:58:33.568 * Slave 127.0.0.1:6380 asks for synchronization
1514:M 14 Aug 15:58:33.568 * Full resync requested by slave 127.0.0.1:6380
1514:M 14 Aug 15:58:33.568 * Starting BGSAVE for SYNC with target: disk
1514:M 14 Aug 15:58:33.569 * Background saving started by pid 1584
1584:C 14 Aug 15:58:33.573 * DB saved on disk
1584:C 14 Aug 15:58:33.573 * RDB: 0 MB of memory used by copy-on-write
1514:M 14 Aug 15:58:33.576 * Background saving terminated with success
1514:M 14 Aug 15:58:33.576 * Synchronization with slave 127.0.0.1:6380 succeeded
</code></pre><p>在<code>slave</code>服务器窗口中，可以看到如下信息：</p>
<pre><code>1579:S 14 Aug 15:58:33.567 * Connecting to MASTER 127.0.0.1:6379
1579:S 14 Aug 15:58:33.567 * MASTER &lt;-&gt; SLAVE sync started
1579:S 14 Aug 15:58:33.568 * Non blocking connect for SYNC fired the event.
1579:S 14 Aug 15:58:33.568 * Master replied to PING, replication can continue...
1579:S 14 Aug 15:58:33.568 * Partial resynchronization not possible (no cached master)
1579:S 14 Aug 15:58:33.569 * Full resync from master: 7f883c61e9326b040b150462901e70afd5c4a49c:0
1579:S 14 Aug 15:58:33.576 * MASTER &lt;-&gt; SLAVE sync: receiving 176 bytes from master
1579:S 14 Aug 15:58:33.577 * MASTER &lt;-&gt; SLAVE sync: Flushing old data
1579:S 14 Aug 15:58:33.577 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory
1579:S 14 Aug 15:58:33.577 * MASTER &lt;-&gt; SLAVE sync: Finished with success
</code></pre><p>从上面的信息中，我们可以知道，<code>slave</code>服务器已经连上<code>master</code>服务器。</p>
<h3 id="测试同步数据"><a href="#测试同步数据" class="headerlink" title="测试同步数据"></a>测试同步数据</h3><p>登录<code>master</code>服务器并在其中插入一个键<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_master/src/</span><br><span class="line">$ ./redis-cli -p 6379</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or <span class="built_in">set</span>)</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> name <span class="string">"Tim Ho"</span></span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line"><span class="string">"Tim Ho"</span></span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure></p>
<p>登录<code>slave</code>服务器并在其中获取一个键<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/hewentian/ProjectD/redis-4.0.11_slave/src/</span><br><span class="line">$ ./redis-cli -p 6380</span><br><span class="line"></span><br><span class="line">127.0.0.1:6380&gt; keys *</span><br><span class="line">(empty list or <span class="built_in">set</span>)</span><br><span class="line">127.0.0.1:6380&gt; keys *</span><br><span class="line">1) <span class="string">"name"</span></span><br><span class="line">127.0.0.1:6380&gt; get name </span><br><span class="line"><span class="string">"Tim Ho"</span></span><br><span class="line">127.0.0.1:6380&gt;</span><br></pre></td></tr></table></figure></p>
<p>至此，主从配置完成。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://github.com/hewentian/2018/08/14/redis-master-slave/" data-id="cjogzpsmz0029vv2itzorqk29" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/redis/">redis</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/bigdata/">bigdata</a><span class="category-list-count">20</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/db/">db</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">7</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">November 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/12/kafka-intro/">kafka 介绍</a>
          </li>
        
          <li>
            <a href="/2018/10/27/kafka-cluster/">kafka 集群的搭建</a>
          </li>
        
          <li>
            <a href="/2018/10/24/kafka-standalone/">kafka 单节点安装</a>
          </li>
        
          <li>
            <a href="/2018/10/05/jenkins-install/">jenkins 学习笔记</a>
          </li>
        
          <li>
            <a href="/2018/10/02/ELK-install/">ELK 日志系统的搭建</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">link</h3>
    <div class="widget">
      <li><a href="https://github.com/hewentian" title="Tim Ho's Blog">我的github</a></li>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Tim Ho<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives/" class="mobile-nav-link">Archives</a>
  
    <a href="/categories/" class="mobile-nav-link">Categories</a>
  
    <a href="/tags/" class="mobile-nav-link">Tags</a>
  
    <a href="/about/" class="mobile-nav-link">About</a>
  
</nav>
    

<!-- <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script> -->
<script src="//code.jquery.com/jquery-2.2.4.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>